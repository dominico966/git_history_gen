"""
ìºì‹± ë° ì»¨í…ìŠ¤íŠ¸ ê°œì„  í…ŒìŠ¤íŠ¸
1. ì›ê²© ì €ì¥ì†Œ í´ë¡  ìºì‹± í…ŒìŠ¤íŠ¸
2. ë³€ê²½ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
"""

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import logging
import time
from src.document_generator import DocumentGenerator
from src.repo_cache import RepoCloneCache

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def test_clone_caching():
    """ì›ê²© ì €ì¥ì†Œ í´ë¡  ìºì‹± í…ŒìŠ¤íŠ¸"""
    logger.info("=" * 60)
    logger.info("1. ì›ê²© ì €ì¥ì†Œ í´ë¡  ìºì‹± í…ŒìŠ¤íŠ¸")
    logger.info("=" * 60)

    test_url = "https://github.com/octocat/Hello-World"

    try:
        # ì²« ë²ˆì§¸ í´ë¡  (ìºì‹œ ë¯¸ìŠ¤)
        logger.info("ì²« ë²ˆì§¸ í´ë¡  (ìºì‹œ ë¯¸ìŠ¤ ì˜ˆìƒ)...")
        start_time = time.time()

        doc_gen1 = DocumentGenerator(test_url, clone_depth=10)
        commits1 = doc_gen1.get_commits(limit=5)

        first_clone_time = time.time() - start_time
        logger.info(f"âœ“ ì²« ë²ˆì§¸ í´ë¡  ì™„ë£Œ: {first_clone_time:.2f}ì´ˆ, {len(commits1)}ê°œ ì»¤ë°‹")

        # ë‘ ë²ˆì§¸ í´ë¡  (ìºì‹œ íˆíŠ¸)
        logger.info("\në‘ ë²ˆì§¸ í´ë¡  (ìºì‹œ íˆíŠ¸ ì˜ˆìƒ)...")
        start_time = time.time()

        doc_gen2 = DocumentGenerator(test_url, clone_depth=10)
        commits2 = doc_gen2.get_commits(limit=5)

        second_clone_time = time.time() - start_time
        logger.info(f"âœ“ ë‘ ë²ˆì§¸ í´ë¡  ì™„ë£Œ: {second_clone_time:.2f}ì´ˆ, {len(commits2)}ê°œ ì»¤ë°‹")

        # ì„±ëŠ¥ ë¹„êµ
        speedup = first_clone_time / second_clone_time if second_clone_time > 0 else 0
        logger.info(f"\nì„±ëŠ¥ ê°œì„ : {speedup:.1f}ë°° ë¹ ë¦„ (ìºì‹œ íš¨ê³¼)")

        if speedup > 2:
            logger.info("âœ“ ìºì‹±ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤!")
        else:
            logger.warning("âš ï¸ ìºì‹± íš¨ê³¼ê°€ ì˜ˆìƒë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤.")

        # ìºì‹œ ì •ë³´ í™•ì¸
        cache = RepoCloneCache()
        cache_info = cache.get_cache_info()
        logger.info(f"\nìºì‹œ ì •ë³´: {cache_info['cached_repos']}ê°œ ì €ì¥ì†Œ ìºì‹œë¨")

        return True

    except Exception as e:
        logger.error(f"âœ— í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)
        return False


def test_change_context():
    """ë³€ê²½ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    logger.info("\n" + "=" * 60)
    logger.info("2. ë³€ê²½ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    logger.info("=" * 60)

    test_url = "https://github.com/octocat/Hello-World"

    try:
        doc_gen = DocumentGenerator(test_url, clone_depth=10)
        commits = doc_gen.get_commits(limit=3)

        logger.info(f"âœ“ {len(commits)}ê°œ ì»¤ë°‹ ì¶”ì¶œ")

        # ê° ì»¤ë°‹ì˜ ë³€ê²½ ì»¨í…ìŠ¤íŠ¸ í™•ì¸
        for i, commit in enumerate(commits, 1):
            logger.info(f"\n--- ì»¤ë°‹ {i} ---")
            logger.info(f"SHA: {commit['id'][:8]}")
            logger.info(f"Message: {commit['message'][:50]}")
            logger.info(f"Files: {len(commit['files'])}")

            # íŒŒì¼ë³„ ì»¨í…ìŠ¤íŠ¸ í™•ì¸
            for file_info in commit['files']:
                file_path = file_info['file']
                logger.info(f"\n  ğŸ“„ {file_path}")
                logger.info(f"     +{file_info['lines_added']} -{file_info['lines_deleted']}")

                # ë³€ê²½ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
                if 'change_context' in file_info:
                    contexts = file_info['change_context']
                    logger.info(f"     âœ“ {len(contexts)}ê°œ ë³€ê²½ ë¸”ë¡ì˜ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œë¨")

                    for j, ctx in enumerate(contexts[:1], 1):  # ì²« ë²ˆì§¸ ë¸”ë¡ë§Œ í‘œì‹œ
                        snippet = ctx['snippet'][:200]  # ì²˜ìŒ 200ìë§Œ
                        logger.info(f"     ë¸”ë¡ {j} (ë¼ì¸ {ctx['start_line']}~):")
                        logger.info(f"     {snippet[:100]}...")
                else:
                    logger.info(f"     â„¹ï¸ ë³€ê²½ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ (ë°”ì´ë„ˆë¦¬ íŒŒì¼ ë˜ëŠ” ì¶”ì¶œ ì‹¤íŒ¨)")

        logger.info("\nâœ“ ë³€ê²½ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return True

    except Exception as e:
        logger.error(f"âœ— í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)
        return False


def test_multiple_repos():
    """ì—¬ëŸ¬ ì €ì¥ì†Œ ìºì‹± í…ŒìŠ¤íŠ¸"""
    logger.info("\n" + "=" * 60)
    logger.info("3. ì—¬ëŸ¬ ì €ì¥ì†Œ ìºì‹± í…ŒìŠ¤íŠ¸")
    logger.info("=" * 60)

    repos = [
        "https://github.com/octocat/Hello-World",
        "https://github.com/octocat/Spoon-Knife"
    ]

    try:
        cache = RepoCloneCache()

        for repo_url in repos:
            logger.info(f"\nì²˜ë¦¬ ì¤‘: {repo_url}")
            doc_gen = DocumentGenerator(repo_url, clone_depth=5)
            commits = doc_gen.get_commits(limit=3)
            logger.info(f"âœ“ {len(commits)}ê°œ ì»¤ë°‹ ì¶”ì¶œ")

        # ìµœì¢… ìºì‹œ ìƒíƒœ
        cache_info = cache.get_cache_info()
        logger.info(f"\nìµœì¢… ìºì‹œ ìƒíƒœ:")
        logger.info(f"  - ìºì‹œëœ ì €ì¥ì†Œ: {cache_info['cached_repos']}ê°œ")
        logger.info(f"  - ìºì‹œ ë””ë ‰í† ë¦¬: {cache_info['cache_dir']}")

        if cache_info['cached_repos'] == len(repos):
            logger.info("âœ“ ëª¨ë“  ì €ì¥ì†Œê°€ ìºì‹œë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            logger.warning(f"âš ï¸ ì˜ˆìƒ: {len(repos)}ê°œ, ì‹¤ì œ: {cache_info['cached_repos']}ê°œ")

        return True

    except Exception as e:
        logger.error(f"âœ— í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)
        return False


def main():
    """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logger.info("\n" + "=" * 60)
    logger.info("ìºì‹± ë° ì»¨í…ìŠ¤íŠ¸ ê°œì„  í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 60)

    results = []

    # 1. í´ë¡  ìºì‹± í…ŒìŠ¤íŠ¸
    results.append(("í´ë¡  ìºì‹±", test_clone_caching()))

    # 2. ë³€ê²½ ì»¨í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸
    results.append(("ë³€ê²½ ì»¨í…ìŠ¤íŠ¸", test_change_context()))

    # 3. ì—¬ëŸ¬ ì €ì¥ì†Œ ìºì‹± í…ŒìŠ¤íŠ¸
    results.append(("ì—¬ëŸ¬ ì €ì¥ì†Œ ìºì‹±", test_multiple_repos()))

    # ê²°ê³¼ ìš”ì•½
    logger.info("\n" + "=" * 60)
    logger.info("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    logger.info("=" * 60)

    for name, result in results:
        status = "âœ“ ì„±ê³µ" if result else "âœ— ì‹¤íŒ¨"
        logger.info(f"{name}: {status}")

    success_count = sum(1 for _, r in results if r)
    logger.info(f"\nì´ {len(results)}ê°œ ì¤‘ {success_count}ê°œ ì„±ê³µ")

    # ìºì‹œ ì •ë¦¬
    logger.info("\nìºì‹œ ì •ë¦¬ ì¤‘...")
    cache = RepoCloneCache()
    cache.clear_all()
    logger.info("âœ“ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

    return 0 if success_count == len(results) else 1


if __name__ == "__main__":
    exit(main())

