"""
Git History Generator - Streamlit Web Application
Git ì €ì¥ì†Œì˜ ì»¤ë°‹ íˆìŠ¤í† ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ëŒ€í™”í˜• ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import streamlit as st
import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.agent import initialize_models
from src.tools import (
    get_commit_summary,
    search_commits,
    analyze_contributors,
    find_frequent_bug_commits
)
from src.indexer import CommitIndexer
from src.repo_cache import RepoCloneCache
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Page configuration
st.set_page_config(
    page_title="Git History Generator",
    page_icon="ğŸ“š",
    layout="wide"
)

# Initialize models (cached)
@st.cache_resource
def get_clients():
    """í´ë¼ì´ì–¸íŠ¸ë“¤ì„ ì´ˆê¸°í™”í•˜ê³  ìºì‹±í•©ë‹ˆë‹¤."""
    try:
        return initialize_models()
    except Exception as e:
        st.error(f"Failed to initialize clients: {e}")
        st.stop()

llm_client, search_client, index_client = get_clients()

# Main UI
st.title("ğŸ“š Git History Generator")
st.markdown("Git ì €ì¥ì†Œì˜ ì»¤ë°‹ íˆìŠ¤í† ë¦¬ë¥¼ ë¶„ì„í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.")

# Sidebar - Settings
with st.sidebar:
    st.header("âš™ï¸ Settings")

    st.subheader("ğŸ“ Repository")
    repo_type = st.radio(
        "Repository Type",
        ["Local Path", "Remote URL"],
        help="ë¡œì»¬ ì €ì¥ì†Œ ë˜ëŠ” ì›ê²© ì €ì¥ì†Œ ì„ íƒ"
    )

    if repo_type == "Local Path":
        repo_path = st.text_input(
            "Local Repository Path",
            value=".",
            help="ë¶„ì„í•  ë¡œì»¬ Git ì €ì¥ì†Œì˜ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
    else:
        repo_path = st.text_input(
            "Remote Repository URL",
            value="",
            placeholder="https://github.com/username/repository",
            help="ì›ê²© Git ì €ì¥ì†Œ URLì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: https://github.com/rust-lang/rust)"
        )
        st.warning("âš ï¸ ì›ê²© ì €ì¥ì†ŒëŠ” ì„ì‹œë¡œ cloneë©ë‹ˆë‹¤. í° ì €ì¥ì†ŒëŠ” ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.divider()

    st.subheader("ê¸°ì—¬ì í‰ê°€ ê¸°ì¤€")
    contributor_criteria = st.text_area(
        "Contributor Evaluation Criteria",
        value="ì»¤ë°‹ ìˆ˜, ë³€ê²½ ë¼ì¸ ìˆ˜, íŒŒì¼ ë³€ê²½ ë¹ˆë„",
        help="ê¸°ì—¬ìë¥¼ í‰ê°€í•  ê¸°ì¤€ì„ ì…ë ¥í•˜ì„¸ìš”"
    )

    st.divider()

    # Index Management
    st.subheader("ğŸ”§ Index Management")
    index_name = os.getenv("AZURE_SEARCH_INDEX_NAME", "git-commits")
    st.info(f"Current Index: `{index_name}`")

    # ì¸ë±ì‹± ì˜µì…˜
    with st.expander("âš™ï¸ Indexing Options", expanded=True):
        col_opt1, col_opt2 = st.columns(2)

        with col_opt1:
            commit_limit = st.number_input(
                "ì»¤ë°‹ ê°œìˆ˜ ì œí•œ",
                min_value=1,
                max_value=1000,
                value=10,
                step=10,
                help="ì¸ë±ì‹±í•  ìµœëŒ€ ì»¤ë°‹ ìˆ˜ (ê¸°ë³¸ê°’: 10)"
            )

            skip_existing = st.checkbox(
                "ì¦ë¶„ ì¸ë±ì‹± (ê¸°ì¡´ ì»¤ë°‹ ê±´ë„ˆë›°ê¸°)",
                value=True,
                help="ì´ë¯¸ ì¸ë±ì‹±ëœ ì»¤ë°‹ì€ ê±´ë„ˆë›°ê³  ìƒˆë¡œìš´ ì»¤ë°‹ë§Œ ì¶”ê°€í•©ë‹ˆë‹¤."
            )

        with col_opt2:
            use_date_filter = st.checkbox(
                "ë‚ ì§œ í•„í„° ì‚¬ìš©",
                value=False,
                help="íŠ¹ì • ê¸°ê°„ì˜ ì»¤ë°‹ë§Œ ì¸ë±ì‹±í•©ë‹ˆë‹¤."
            )

            if use_date_filter:
                since_date = st.date_input(
                    "ì‹œì‘ ë‚ ì§œ",
                    value=None,
                    help="ì´ ë‚ ì§œ ì´í›„ì˜ ì»¤ë°‹ë§Œ ì¸ë±ì‹±"
                )
                until_date = st.date_input(
                    "ì¢…ë£Œ ë‚ ì§œ",
                    value=None,
                    help="ì´ ë‚ ì§œ ì´ì „ì˜ ì»¤ë°‹ë§Œ ì¸ë±ì‹±"
                )
            else:
                since_date = None
                until_date = None

        # ì›ê²© ì €ì¥ì†Œ ê²½ê³ 
        if repo_type == "Remote URL":
            st.info("ğŸ“¦ ì›ê²© ì €ì¥ì†ŒëŠ” ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤ (shallow clone ì—†ìŒ)")

    # ë¹„ìš© ê²½ê³  í‘œì‹œ
    if commit_limit > 100:
        st.warning(f"âš ï¸ {commit_limit}ê°œ ì»¤ë°‹ ì¸ë±ì‹± ì‹œ API ë¹„ìš©ì´ ë§ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")

    col1, col2 = st.columns(2)

    with col1:
        if st.button("ğŸ“¥ Index Repository", use_container_width=True):
            if not repo_path or (repo_type == "Remote URL" and not repo_path.startswith(('http://', 'https://', 'git@'))):
                st.error("ì˜¬ë°”ë¥¸ ì €ì¥ì†Œ ê²½ë¡œ ë˜ëŠ” URLì„ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                with st.spinner("Indexing commits..."):
                    try:
                        indexer = CommitIndexer(
                            search_client,
                            index_client,
                            llm_client,
                            index_name
                        )

                        # Create index if not exists
                        indexer.create_index_if_not_exists()

                        # Index repository with options
                        if repo_type == "Remote URL":
                            st.info(f"ğŸ”„ ì €ì¥ì†Œ ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...")

                        # ë‚ ì§œ ë³€í™˜
                        since_str = since_date.isoformat() if use_date_filter and since_date else None
                        until_str = until_date.isoformat() if use_date_filter and until_date else None

                        # ì¸ë±ì‹± ì •ë³´ í‘œì‹œ
                        info_parts = [f"ì»¤ë°‹ ìˆ˜: {commit_limit}"]
                        if since_str:
                            info_parts.append(f"ì‹œì‘: {since_str}")
                        if until_str:
                            info_parts.append(f"ì¢…ë£Œ: {until_str}")
                        if skip_existing:
                            info_parts.append("ì¦ë¶„ ì¸ë±ì‹±")

                        st.info(f"ğŸ“Š ì¸ë±ì‹± ì˜µì…˜: {', '.join(info_parts)}")

                        count = indexer.index_repository(
                            repo_path,
                            limit=commit_limit,
                            since=since_str,
                            until=until_str,
                            skip_existing=skip_existing
                        )
                        st.success(f"âœ“ Successfully indexed {count} commits!")

                    except Exception as e:
                        error_msg = str(e)

                        # íŒŒì¼ëª…ì´ ë„ˆë¬´ ê¸´ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
                        if 'Filename too long' in error_msg or 'íŒŒì¼ ê²½ë¡œê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤' in error_msg:
                            st.error("âŒ íŒŒì¼ ê²½ë¡œê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (Windows ì œí•œ)")

                            with st.expander("ğŸ“‹ í•´ê²° ë°©ë²• ë³´ê¸°", expanded=True):
                                st.markdown("""
                                ### Windowsì—ì„œ ê¸´ ê²½ë¡œ ì§€ì› í™œì„±í™” í•„ìš”
                                
                                **ë°©ë²• 1: Git ì„¤ì • (ê¶Œì¥)**
                                1. **ê´€ë¦¬ì ê¶Œí•œ**ìœ¼ë¡œ PowerShell ì‹¤í–‰
                                2. ë‹¤ìŒ ëª…ë ¹ ì‹¤í–‰:
                                ```powershell
                                git config --system core.longpaths true
                                ```
                                3. í”„ë¡œê·¸ë¨ ì¬ì‹œì‘
                                
                                **ë°©ë²• 2: Windows ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì„¤ì •**
                                1. **ê´€ë¦¬ì ê¶Œí•œ**ìœ¼ë¡œ ë ˆì§€ìŠ¤íŠ¸ë¦¬ í¸ì§‘ê¸° ì‹¤í–‰ (`regedit`)
                                2. ë‹¤ìŒ ê²½ë¡œë¡œ ì´ë™:
                                   `HKLM\\SYSTEM\\CurrentControlSet\\Control\\FileSystem`
                                3. `LongPathsEnabled` ê°’ì„ `1`ë¡œ ì„¤ì • (DWORD)
                                4. ì‹œìŠ¤í…œ ì¬ì‹œì‘
                                
                                **ë°©ë²• 3: ë¡œì»¬ ì €ì¥ì†Œ ì‚¬ìš©**
                                - ì›ê²© ì €ì¥ì†Œë¥¼ ë¨¼ì € ë¡œì»¬ì— cloneí•œ í›„ ë¡œì»¬ ê²½ë¡œ ì‚¬ìš©
                                """)

                            st.info("ğŸ’¡ ì„¤ì • í›„ í”„ë¡œê·¸ë¨ì„ ì¬ì‹œì‘í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                        else:
                            st.error(f"Indexing failed: {e}")

                        logger.exception("Indexing error")

    with col2:
        delete_index_btn = st.button("ğŸ—‘ï¸ Delete Index", use_container_width=True)

        if delete_index_btn:
            if st.session_state.get('confirm_delete_index'):
                try:
                    indexer = CommitIndexer(
                        search_client,
                        index_client,
                        llm_client,
                        index_name
                    )
                    indexer.delete_index()
                    st.success("âœ“ Index deleted")
                    st.session_state.confirm_delete_index = False
                except Exception as e:
                    st.error(f"Delete failed: {e}")
            else:
                st.session_state.confirm_delete_index = True
                st.session_state.confirm_clear_cache = False  # ë‹¤ë¥¸ ë²„íŠ¼ ìƒíƒœ ë¦¬ì…‹
                st.warning("âš ï¸ Click again to confirm deletion")

    # ìºì‹œ ê´€ë¦¬
    st.divider()
    st.subheader("ğŸ’¾ Cache Management")

    cache = RepoCloneCache()
    cache_info = cache.get_cache_info()

    col_cache1, col_cache2 = st.columns(2)

    with col_cache1:
        st.metric("Cached Repositories", cache_info['cached_repos'])
        if cache_info['cache_dir']:
            st.caption(f"Cache dir: `{cache_info['cache_dir']}`")

    with col_cache2:
        clear_cache_btn = st.button("ğŸ§¹ Clear Cache", use_container_width=True)

        if clear_cache_btn:
            if st.session_state.get('confirm_clear_cache'):
                try:
                    cache.clear_all()
                    st.success("âœ“ Cache cleared")
                    st.session_state.confirm_clear_cache = False
                    st.rerun()
                except Exception as e:
                    st.error(f"Failed to clear cache: {e}")
            else:
                st.session_state.confirm_clear_cache = True
                st.session_state.confirm_delete_index = False  # ë‹¤ë¥¸ ë²„íŠ¼ ìƒíƒœ ë¦¬ì…‹
                st.warning("âš ï¸ Click again to confirm cache clearing")

# Main content - Tabs
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ“ Commit Summary",
    "ğŸ” Search Commits",
    "ğŸ‘¥ Contributors Analysis",
    "ğŸ› Bug Commits"
])

# Tab 1: Commit Summary
with tab1:
    st.header("ìµœê·¼ ì»¤ë°‹ ìš”ì•½")
    st.markdown("LLMì„ í™œìš©í•˜ì—¬ ìµœê·¼ ì»¤ë°‹ë“¤ì„ ë¶„ì„í•˜ê³  ìš”ì•½í•©ë‹ˆë‹¤.")

    col1, col2 = st.columns([3, 1])
    with col1:
        summary_limit = st.slider("ë¶„ì„í•  ì»¤ë°‹ ìˆ˜", 10, 200, 50)
    with col2:
        generate_summary_btn = st.button("ğŸ“Š Generate Summary", use_container_width=True)

    if generate_summary_btn:
        with st.spinner("Analyzing repository..."):
            try:
                summary = get_commit_summary(repo_path, llm_client, limit=summary_limit)
                st.markdown("### ğŸ“‹ ë¶„ì„ ê²°ê³¼")
                st.markdown(summary)
            except Exception as e:
                st.error(f"Error: {e}")
                logger.exception("Failed to generate summary")

# Tab 2: Search Commits
with tab2:
    st.header("ì»¤ë°‹ ê²€ìƒ‰")
    st.markdown("ìì—°ì–´ ì¿¼ë¦¬ë¡œ ì»¤ë°‹ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤ (ë²¡í„° + í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰).")

    col1, col2 = st.columns([4, 1])
    with col1:
        query = st.text_input(
            "Search Query",
            placeholder="ì˜ˆ: ë¡œê·¸ì¸ ê¸°ëŠ¥ ë²„ê·¸ ìˆ˜ì •",
            help="ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ìì—°ì–´ë¡œ ì…ë ¥í•˜ì„¸ìš”"
        )
    with col2:
        top_k = st.number_input("Results", 5, 50, 10)

    search_btn = st.button("ğŸ” Search", use_container_width=True)

    if search_btn and query:
        with st.spinner("Searching..."):
            try:
                results = search_commits(query, search_client, llm_client, top=top_k)

                if results:
                    st.success(f"Found {len(results)} results")

                    for i, result in enumerate(results, 1):
                        with st.expander(f"#{i} [{result['date']}] {result['message'][:80]}...", expanded=(i == 1)):
                            col1, col2 = st.columns([3, 1])
                            with col1:
                                st.markdown(f"**Author:** {result['author']}")
                                st.markdown(f"**Message:** {result['message']}")
                                st.markdown(f"**Files:** {result['files']}")

                                # ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„° í‘œì‹œ
                                if result.get('context'):
                                    st.markdown(f"**ë³€ê²½ ë¬¸ë§¥:** {result['context']}")

                                if result.get('functions'):
                                    st.markdown(f"**ìˆ˜ì •ëœ í•¨ìˆ˜:** {result['functions']}")

                                if result.get('classes'):
                                    st.markdown(f"**ìˆ˜ì •ëœ í´ë˜ìŠ¤:** {result['classes']}")

                                if result.get('impact'):
                                    with st.expander("ì˜í–¥ ë²”ìœ„ ë³´ê¸°"):
                                        st.text(result['impact'])

                            with col2:
                                st.metric("Score", f"{result['score']:.2f}")
                                st.metric("Changes", result['changes'])
                                st.metric("Complexity", result.get('complexity', 'unknown'))
                                st.info(f"ê´€ê³„: {result.get('relation', 'N/A')}")

                            st.code(result['commit_id'], language=None)
                else:
                    st.warning("No results found")

            except Exception as e:
                st.error(f"Search failed: {e}")
                logger.exception("Search error")

# Tab 3: Contributors Analysis
with tab3:
    st.header("ê¸°ì—¬ì ë¶„ì„")
    st.markdown("ì €ì¥ì†Œì˜ ê¸°ì—¬ìë“¤ì„ ë¶„ì„í•˜ê³  í‰ê°€í•©ë‹ˆë‹¤.")

    col1, col2 = st.columns([3, 1])
    with col1:
        contrib_limit = st.slider("ë¶„ì„í•  ì»¤ë°‹ ìˆ˜", 50, 200, 100, key="contrib_limit")
    with col2:
        analyze_btn = st.button("ğŸ“Š Analyze", use_container_width=True)

    if analyze_btn:
        with st.spinner("Analyzing contributors..."):
            try:
                result = analyze_contributors(
                    repo_path,
                    criteria=contributor_criteria,
                    limit=contrib_limit
                )

                if "error" in result:
                    st.error(f"Error: {result['error']}")
                else:
                    # Overview metrics
                    col1, col2, col3 = st.columns(3)
                    col1.metric("Total Contributors", result['total_contributors'])
                    col2.metric("Total Commits", result['total_commits'])
                    col3.metric("Avg Commits/Contributor",
                               f"{result['total_commits'] / result['total_contributors']:.1f}")

                    st.markdown("### ğŸ“Š ê¸°ì—¬ìë³„ ìƒì„¸ í†µê³„")

                    # Top contributors table
                    for i, contrib in enumerate(result['contributors'][:10], 1):
                        with st.expander(f"#{i} {contrib['name']} - {contrib['commits']} commits",
                                       expanded=(i <= 3)):
                            col1, col2, col3, col4 = st.columns(4)
                            col1.metric("Commits", contrib['commits'])
                            col2.metric("Files Changed", contrib['files_changed'])
                            col3.metric("Lines Added", contrib['lines_added'])
                            col4.metric("Lines Deleted", contrib['lines_deleted'])

                            st.markdown("**Recent Commits:**")
                            for commit in contrib['recent_commits']:
                                st.markdown(f"- `{commit['date']}`: {commit['message']}")

            except Exception as e:
                st.error(f"Analysis failed: {e}")
                logger.exception("Contributor analysis error")

# Tab 4: Bug Commits
with tab4:
    st.header("ë²„ê·¸ ê´€ë ¨ ì»¤ë°‹")
    st.markdown("ë²„ê·¸ ìˆ˜ì • ì»¤ë°‹ì„ ì°¾ì•„ ë¶„ì„í•©ë‹ˆë‹¤.")

    col1, col2 = st.columns([3, 1])
    with col1:
        bug_limit = st.slider("ë¶„ì„í•  ì»¤ë°‹ ìˆ˜", 50, 500, 200, key="bug_limit")
    with col2:
        find_bugs_btn = st.button("ğŸ› Find Bugs", use_container_width=True)

    if find_bugs_btn:
        with st.spinner("Finding bug-related commits..."):
            try:
                bug_commits = find_frequent_bug_commits(repo_path, llm_client, limit=bug_limit)

                if bug_commits:
                    st.success(f"Found {len(bug_commits)} bug-related commits")

                    # Statistics
                    col1, col2 = st.columns(2)
                    col1.metric("Total Bug Commits", len(bug_commits))
                    col2.metric("Bug Rate", f"{len(bug_commits)/bug_limit*100:.1f}%")

                    st.markdown("### ğŸ› Bug Fix Commits")

                    for commit in bug_commits[:20]:
                        with st.expander(f"[{commit['date']}] {commit['message'][:80]}..."):
                            st.markdown(f"**Commit ID:** `{commit['id']}`")
                            st.markdown(f"**Author:** {commit['author']}")
                            st.markdown(f"**Date:** {commit['date']}")
                            st.markdown(f"**Files Changed:** {commit['files_changed']}")
                            st.markdown(f"**Message:** {commit['message']}")
                else:
                    st.info("No bug-related commits found")

            except Exception as e:
                st.error(f"Error: {e}")
                logger.exception("Bug commit search error")

# Footer
st.divider()
st.markdown("---")
st.markdown("ğŸš€ **Git History Generator** | Powered by Azure OpenAI & Azure AI Search")
