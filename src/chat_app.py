"""
Chainlit ê¸°ë°˜ ëŒ€í™”í˜• Git íˆìŠ¤í† ë¦¬ ë¶„ì„ ì±„íŒ… ì•±
í”„ë¡¬í”„íŠ¸ëŠ” êµ¬ì¡°í™”ëœ ê°ì²´ë¡œ ê´€ë¦¬í•˜ë©° ì—¬ëŸ¬ ì¤„ ë¬¸ìì—´(''' or \"\"\") ì‚¬ìš© ê¸ˆì§€
"""

import json
import logging
import os
import sys
from pathlib import Path
from typing import Dict, Any, Optional

import chainlit as cl
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from dotenv import load_dotenv
from openai import AzureOpenAI

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.tools import (
    get_commit_summary,
    search_commits,
    analyze_contributors,
    find_frequent_bug_commits,
    get_commit_count
)
from src.online_reader import (
    OnlineRepoReader,
    read_file_from_commit,
    get_file_context,
    get_readme_content,
    get_commit_diff
)
from src.indexer import CommitIndexer
from azure.search.documents.indexes import SearchIndexClient
from src.index_manager import IndexManager, format_index_statistics

from datetime import datetime
TODAY=datetime.today().strftime('%Y-%m-%d')

load_dotenv()
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ì•ˆì „ ì¥ì¹˜: ìµœëŒ€ê°’ ì œí•œ (í† í°/ë¹„ìš© í­íƒ„ ë°©ì§€)
MAX_COMMIT_LIMIT = int(os.getenv("MAX_COMMIT_LIMIT", "1000"))
MAX_SEARCH_TOP = int(os.getenv("MAX_SEARCH_TOP", "50"))
MAX_CONTRIBUTOR_LIMIT = int(os.getenv("MAX_CONTRIBUTOR_LIMIT", "1000"))
DEFAULT_INDEX_LIMIT = int(os.getenv("DEFAULT_INDEX_LIMIT", "500"))

# SocketIO í˜ì´ë¡œë“œ ì œí•œ
MAX_TOOL_RESULT_DISPLAY = 500  # Stepì— í‘œì‹œí•  ìµœëŒ€ ë¬¸ì ìˆ˜
MAX_TOOL_RESULT_TO_LLM = 10000  # LLMì— ì „ë‹¬í•  ìµœëŒ€ ë¬¸ì ìˆ˜
MAX_CONVERSATION_MESSAGES = 20  # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ìµœê·¼ Nê°œ ë©”ì‹œì§€

# ----- í”„ë¡¬í”„íŠ¸ ì •ì˜ (ì—¬ëŸ¬ ì¤„ ë¬¸ìì—´ ê¸ˆì§€) -----
SYSTEM_PROMPT_PARTS = [
    # ë‚ ì§œëŠ” ì‹¤í–‰ ì‹œ ì£¼ì…ë¨
    f"Git íˆìŠ¤í† ë¦¬ ë¶„ì„ ì „ë¬¸ê°€. ì˜¤ëŠ˜: {TODAY}",
    "",
    "# í•µì‹¬ ê·œì¹™",
    "- í•œêµ­ì–´ êµ¬ì¡°í™”ëœ ë‹µë³€. í™•ì¸ ì§ˆë¬¸ ê¸ˆì§€",
    "- ë„êµ¬ ë°”ë¡œ ì‹¤í–‰ â†’ ê²°ê³¼ ë¶„ì„ â†’ ëª…í™•í•œ ì„¤ëª…",
    "- ê²€ìƒ‰ì€ ì˜ì–´ë§Œ. ë‹¤ë¥¸ ì–¸ì–´ì‹œ ë²ˆì—­",
    "",
    "# ì¸ë±ì‹± ì „ëµ",
    f"1. ë¶„ì„ ìš”ì²­ì‹œ: list_indexed_repositories â†’ get_commit_count í™•ì¸",
    f"2. ê¸°ë³¸: ìµœê·¼ {DEFAULT_INDEX_LIMIT}ê°œ, HEADë¶€í„° ì‹œì‘, skip_existing=true",
    "3. ì¦ë¶„: skip_offsetìœ¼ë¡œ ê³¼ê±° ì»¤ë°‹ ì¶”ê°€",
    "4. **ì¤‘ìš”**: ì¸ë±ì‹±ìˆ˜ < ì „ì²´ìˆ˜ â†’ ì¶”ê°€ í•„ìš”. 'ì „ë¶€' ìš”ì²­ì‹œ 100% ì™„ë£Œê¹Œì§€",
    "5. ê·œëª¨ë³„: ~100(ê¸°ë³¸), 100~500(skip_offset), 500+(ë‚ ì§œë²”ìœ„)",
    "",
    "# ì¦ë¶„ ì¸ë±ì‹± ê²°ê³¼ í•´ì„",
    "- ë¡œê·¸ì— 'Skipped N already indexed commits' í‘œì‹œ â†’ **ì •ìƒ ë™ì‘**",
    "- ì´ë¯¸ ì¸ë±ì‹±ëœ ì»¤ë°‹ì€ ìë™ìœ¼ë¡œ ê±´ë„ˆë›°ê³ , ìƒˆë¡œìš´ ì»¤ë°‹ë§Œ ì¸ë±ì‹±í•¨",
    "- ì˜ˆ: 436ê°œ ì¶”ì¶œ â†’ 100ê°œ ê±´ë„ˆëœ€ â†’ 336ê°œ ì¸ë±ì‹± = **336ê°œ ì¶”ê°€ë¨**",
    "- ì‚¬ìš©ìì—ê²ŒëŠ” **ìƒˆë¡œ ì¶”ê°€ëœ ê°œìˆ˜**ì™€ **ì „ì²´ ì¸ë±ì‹± í˜„í™©**ì„ í•¨ê»˜ ì„¤ëª…",
    "",
    "# 'ì „ì²´' ì¸ë±ì‹± ìš”ì²­ ì²˜ë¦¬",
    "- **'ì „ë¶€', 'ë‹¤ í•´', 'ì „ì²´', 'ëª¨ë“ ' ë“±ì˜ ìš”ì²­ ì‹œ**:",
    "  1. get_commit_countë¡œ ì „ì²´ ì»¤ë°‹ ê°œìˆ˜(N) í™•ì¸",
    "  2. list_indexed_repositoriesë¡œ ì´ë¯¸ ì¸ë±ì‹±ëœ ê°œìˆ˜(M) í™•ì¸",
    "  3. index_repository í˜¸ì¶œ ì‹œ limit=N ì„¤ì • (ì¦ë¶„ ì¸ë±ì‹± ìë™ ì ìš©ë¨)",
    "  4. ì™„ë£Œ í›„ ì‹¤ì œ ì¸ë±ì‹±ëœ ê°œìˆ˜ í™•ì¸ ë° ê²€ì¦",
    "- **ì ˆëŒ€ limit ì—†ì´ í˜¸ì¶œí•˜ì§€ ë§ ê²ƒ** (ê¸°ë³¸ê°’ 100ê°œë§Œ ì²˜ë¦¬ë¨)",
    "",
    "# ìì—°ì–´ ì¸ë±ì‹± ìš”ì²­",
    "- **'ì˜¬í•´', '2025ë…„'**: since=2025-01-01, until=2025-12-31 ìë™ ì„¤ì •",
    "- **'ìµœê·¼'**: limit=500 ê¶Œì¥",
    "- **ë‚ ì§œ ì§€ì •**: since/until íŒŒë¼ë¯¸í„° ì‚¬ìš© (YYYY-MM-DD)",
    "- UIì—ì„œë„ í‚¤ì›Œë“œ ì…ë ¥ ê°€ëŠ¥: 'ì˜¬í•´', 'ì „ì²´', 'ìµœê·¼', ë‚ ì§œ",
    "",
    "# í•„ìˆ˜ íŒë‹¨ ì›ì¹™",
    "- **ì¶”ì¸¡ ê¸ˆì§€**: get_commit_count â†” list_indexed_repositories ë¹„êµ í•„ìˆ˜",
    "- ë¶€ë¶„ ì¸ë±ì‹± â†’ ì¶”ê°€ ì‘ì—…, ì™„ì „ ì¸ë±ì‹± â†’ \"ì´ë¯¸ ìˆìŒ\" ê°€ëŠ¥",
    "- ë‚ ì§œë²”ìœ„ í›„ ì‹¤ì œ ê²°ê³¼ ê²€ì¦",
    "",
    "# ë„êµ¬",
    "- search_commits: ìë™ UI í™•ì¸",
    "- index_repository: ëŒ€ìš©ëŸ‰ì‹œ ìë™ UI í™•ì¸",
    "- ë‚ ì§œ: YYYY-MM-DD í˜•ì‹",
]


def _build_system_prompt(today: str) -> str:
    """SYSTEM_PROMPT_PARTSë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ì£¼ì…í•´ ìµœì¢… í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±"""
    # ì—¬ëŸ¬ ì¤„ ë¬¸ìì—´ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ë¼ì¸ ë‹¨ìœ„ë¡œ ê²°í•©
    lines = []
    for part in SYSTEM_PROMPT_PARTS:
        lines.append(part.replace("{TODAY}", today))
    return "\n".join(lines)


# ëª¨ë“ˆ import ì‹œì ì˜ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸(í…ŒìŠ¤íŠ¸ì—ì„œ ì‚¬ìš©). ë™ì  ë‚ ì§œëŠ” get_system_prompt()ë¥¼ ê¶Œì¥
try:
    from datetime import datetime
    SYSTEM_PROMPT = _build_system_prompt(datetime.now().strftime("%Y-%m-%d"))
except Exception:
    # ë‚ ì§œ ìƒì„± ì‹¤íŒ¨ ì‹œì—ë„ ìƒìˆ˜ê°€ ì¡´ì¬í•˜ë„ë¡ fallback
    SYSTEM_PROMPT = _build_system_prompt("0000-00-00")


def get_system_prompt() -> str:
    """ì••ì¶•ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - í•µì‹¬ ê·œì¹™ë§Œ í¬í•¨ (ë™ì  ë‚ ì§œ ì£¼ì…)"""
    from datetime import datetime
    today = datetime.now().strftime("%Y-%m-%d")
    return _build_system_prompt(today)

AVAILABLE_TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "get_commit_count",
            "description": "ì €ì¥ì†Œì˜ ì´ ì»¤ë°‹ ê°œìˆ˜ë¥¼ ë¹ ë¥´ê²Œ í™•ì¸í•©ë‹ˆë‹¤. ë‚ ì§œ ë²”ìœ„ë¥¼ ì§€ì •í•˜ì—¬ íŠ¹ì • ê¸°ê°„ì˜ ì»¤ë°‹ë§Œ ì…€ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¸ë±ì‹± ì „ì— ì €ì¥ì†Œ ê·œëª¨ë¥¼ íŒŒì•…í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "repo_path": {
                        "type": "string",
                        "description": "Git ì €ì¥ì†Œ ê²½ë¡œ (ë¡œì»¬ ê²½ë¡œ ë˜ëŠ” GitHub URL)"
                    },
                    "since": {
                        "type": "string",
                        "description": "ì‹œì‘ ë‚ ì§œ (ISO 8601 í˜•ì‹, ì˜ˆ: 2024-01-01). ì´ ë‚ ì§œ ì´í›„ì˜ ì»¤ë°‹ë§Œ ì…‰ë‹ˆë‹¤."
                    },
                    "until": {
                        "type": "string",
                        "description": "ì¢…ë£Œ ë‚ ì§œ (ISO 8601 í˜•ì‹, ì˜ˆ: 2024-12-31). ì´ ë‚ ì§œ ì´ì „ì˜ ì»¤ë°‹ë§Œ ì…‰ë‹ˆë‹¤."
                    }
                },
                "required": ["repo_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_commit_summary",
            "description": "Git ì €ì¥ì†Œì˜ ìµœê·¼ ì»¤ë°‹ë“¤ì„ ìš”ì•½í•©ë‹ˆë‹¤. ìµœê·¼ ë³€ê²½ì‚¬í•­, ì£¼ìš” ê¸°ì—¬ì, íŠ¸ë Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ë¡œì»¬ Git íˆìŠ¤í† ë¦¬ì—ì„œ ì§ì ‘ ì½ì–´ì˜µë‹ˆë‹¤. ë” ì •ë°€í•œ ê²€ìƒ‰ì´ í•„ìš”í•˜ë©´ ì €ì¥ì†Œë¥¼ ì¸ë±ì‹±í•œ í›„ search_commitsë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
            "parameters": {
                "type": "object",
                "properties": {
                    "repo_path": {
                        "type": "string",
                        "description": "Git ì €ì¥ì†Œ ê²½ë¡œ (ë¡œì»¬ ê²½ë¡œ ë˜ëŠ” GitHub URL)"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "ë¶„ì„í•  ì»¤ë°‹ ìˆ˜ (ê¸°ë³¸ê°’: 50)",
                        "default": 50
                    }
                },
                "required": ["repo_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_commits",
            "description": "ìì—°ì–´ ì¿¼ë¦¬ë¡œ ì»¤ë°‹ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤. íŠ¹ì • ê¸°ëŠ¥, ë²„ê·¸, íŒŒì¼ ë“±ê³¼ ê´€ë ¨ëœ ì»¤ë°‹ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¸ë±ì‹±ë˜ì§€ ì•Šì€ ì €ì¥ì†Œì˜ ê²½ìš° ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ í™•ì¸ì„ ìš”ì²­í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "ê²€ìƒ‰ ì¿¼ë¦¬ (ìì—°ì–´)"
                    },
                    "top": {
                        "type": "integer",
                        "description": "ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 10)",
                        "default": 10
                    },
                    "repo_path": {
                        "type": "string",
                        "description": "íŠ¹ì • ì €ì¥ì†Œë§Œ ê²€ìƒ‰ (ì„ íƒì )"
                    }
                },
                "required": ["query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "analyze_contributors",
            "description": "ê¸°ì—¬ìë³„ í™œë™ì„ ë¶„ì„í•©ë‹ˆë‹¤. ì»¤ë°‹ ìˆ˜, ë³€ê²½ ë¼ì¸ ìˆ˜, ìµœê·¼ í™œë™ ë“±ì„ ì œê³µí•©ë‹ˆë‹¤. ë‚ ì§œ ë²”ìœ„ë¥¼ ì§€ì •í•˜ì—¬ íŠ¹ì • ê¸°ê°„ì˜ ê¸°ì—¬ì í™œë™ë§Œ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "repo_path": {
                        "type": "string",
                        "description": "Git ì €ì¥ì†Œ ê²½ë¡œ"
                    },
                    "criteria": {
                        "type": "string",
                        "description": "í‰ê°€ ê¸°ì¤€ (ì„ íƒì , ê¸°ë³¸ê°’: ì»¤ë°‹ ìˆ˜, ë³€ê²½ ë¼ì¸ ìˆ˜)"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "ë¶„ì„í•  ì»¤ë°‹ ìˆ˜ (ì„ íƒì )"
                    },
                    "since": {
                        "type": "string",
                        "description": "ì‹œì‘ ë‚ ì§œ (ISO 8601 í˜•ì‹, ì˜ˆ: 2024-01-01). ì´ ë‚ ì§œ ì´í›„ì˜ ì»¤ë°‹ë§Œ ë¶„ì„í•©ë‹ˆë‹¤."
                    },
                    "until": {
                        "type": "string",
                        "description": "ì¢…ë£Œ ë‚ ì§œ (ISO 8601 í˜•ì‹, ì˜ˆ: 2024-12-31). ì´ ë‚ ì§œ ì´ì „ì˜ ì»¤ë°‹ë§Œ ë¶„ì„í•©ë‹ˆë‹¤."
                    }
                },
                "required": ["repo_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "find_bug_commits",
            "description": "ë²„ê·¸ ìˆ˜ì •ê³¼ ê´€ë ¨ëœ ì»¤ë°‹ì„ ì°¾ìŠµë‹ˆë‹¤. ì»¤ë°‹ ë©”ì‹œì§€ì—ì„œ 'fix', 'bug', 'issue' ë“±ì˜ í‚¤ì›Œë“œë¥¼ íƒì§€í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "repo_path": {
                        "type": "string",
                        "description": "Git ì €ì¥ì†Œ ê²½ë¡œ"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "ë¶„ì„í•  ì»¤ë°‹ ìˆ˜ (ê¸°ë³¸ê°’: 200)",
                        "default": 200
                    }
                },
                "required": ["repo_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_github_repo",
            "description": "GitHubì—ì„œ ì €ì¥ì†Œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. í‚¤ì›Œë“œë¡œ ê´€ë ¨ ì €ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "ê²€ìƒ‰ í‚¤ì›Œë“œ"
                    },
                    "max_results": {
                        "type": "integer",
                        "description": "ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 5)",
                        "default": 5
                    }
                },
                "required": ["query"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "read_file_from_commit",
            "description": "íŠ¹ì • ì»¤ë°‹ì—ì„œ íŒŒì¼ ë‚´ìš©ì„ ì½ìŠµë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "repo_path": {
                        "type": "string",
                        "description": "Git ì €ì¥ì†Œ ê²½ë¡œ"
                    },
                    "commit_sha": {
                        "type": "string",
                        "description": "ì»¤ë°‹ í•´ì‹œ"
                    },
                    "file_path": {
                        "type": "string",
                        "description": "íŒŒì¼ ê²½ë¡œ"
                    }
                },
                "required": ["repo_path", "commit_sha", "file_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_file_context",
            "description": "ì»¤ë°‹ì—ì„œ ë³€ê²½ëœ íŒŒì¼ì˜ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ì™€ diffë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "repo_path": {
                        "type": "string",
                        "description": "Git ì €ì¥ì†Œ ê²½ë¡œ"
                    },
                    "commit_sha": {
                        "type": "string",
                        "description": "ì»¤ë°‹ í•´ì‹œ"
                    },
                    "file_path": {
                        "type": "string",
                        "description": "íŒŒì¼ ê²½ë¡œ"
                    }
                },
                "required": ["repo_path", "commit_sha", "file_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_commit_diff",
            "description": "íŠ¹ì • ì»¤ë°‹ì˜ ì „ì²´ ë³€ê²½ì‚¬í•­(diff)ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. ì–´ë–¤ íŒŒì¼ì´ ì–´ë–»ê²Œ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í•œëˆˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "repo_path": {
                        "type": "string",
                        "description": "Git ì €ì¥ì†Œ ê²½ë¡œ"
                    },
                    "commit_sha": {
                        "type": "string",
                        "description": "ì»¤ë°‹ í•´ì‹œ ë˜ëŠ” ì»¤ë°‹ ID"
                    },
                    "max_files": {
                        "type": "integer",
                        "description": "í‘œì‹œí•  ìµœëŒ€ íŒŒì¼ ìˆ˜ (ê¸°ë³¸ê°’: 10)",
                        "default": 10
                    }
                },
                "required": ["repo_path", "commit_sha"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_readme",
            "description": "ì €ì¥ì†Œì˜ README íŒŒì¼ ë‚´ìš©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "repo_path": {
                        "type": "string",
                        "description": "Git ì €ì¥ì†Œ ê²½ë¡œ"
                    }
                },
                "required": ["repo_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "set_current_repository",
            "description": "í˜„ì¬ ì‘ì—…í•  ì €ì¥ì†Œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ì´í›„ ë‹¤ë¥¸ ë„êµ¬ í˜¸ì¶œ ì‹œ ì´ ì €ì¥ì†Œê°€ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "repo_path": {
                        "type": "string",
                        "description": "Git ì €ì¥ì†Œ ê²½ë¡œ (ë¡œì»¬ ê²½ë¡œ ë˜ëŠ” GitHub URL)"
                    }
                },
                "required": ["repo_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "index_repository",
            "description": "Git ì €ì¥ì†Œë¥¼ Azure AI Searchì— ì¸ë±ì‹±í•©ë‹ˆë‹¤. skip_offsetì„ ì‚¬ìš©í•˜ë©´ ì´ë¯¸ ì¸ë±ì‹±ëœ ì»¤ë°‹ ì´í›„ì˜ ê³¼ê±° ì»¤ë°‹ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆ: ì´ë¯¸ 100ê°œ ì¸ë±ì‹± â†’ skip_offset=100, limit=50ìœ¼ë¡œ 101~150ë²ˆì§¸ ì»¤ë°‹ ì¶”ê°€ ê°€ëŠ¥. ì£¼ì˜: ë‚ ì§œ ë²”ìœ„(since/until) ì‚¬ìš© ì‹œ ì‹¤ì œ ì»¤ë°‹ ì¡´ì¬ ì—¬ë¶€ì— ë”°ë¼ ì¸ë±ì‹± ê°œìˆ˜ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ. ì¸ë±ì‹± í›„ get_repository_infoë¡œ ì‹¤ì œ ê²°ê³¼ í™•ì¸ ê¶Œì¥.",
            "parameters": {
                "type": "object",
                "properties": {
                    "repo_path": {
                        "type": "string",
                        "description": "Git ì €ì¥ì†Œ ê²½ë¡œ (ë¡œì»¬ ê²½ë¡œ ë˜ëŠ” GitHub URL)"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "ì¸ë±ì‹±í•  ìµœëŒ€ ì»¤ë°‹ ìˆ˜ (ì„ íƒì )"
                    },
                    "since": {
                        "type": "string",
                        "description": "ì‹œì‘ ë‚ ì§œ ISO 8601 í˜•ì‹ (ì„ íƒì , ì˜ˆ: 2024-01-01)"
                    },
                    "until": {
                        "type": "string",
                        "description": "ì¢…ë£Œ ë‚ ì§œ ISO 8601 í˜•ì‹ (ì„ íƒì , ì˜ˆ: 2024-12-31)"
                    },
                    "skip_existing": {
                        "type": "boolean",
                        "description": "ì´ë¯¸ ì¸ë±ì‹±ëœ ì»¤ë°‹ ê±´ë„ˆë›°ê¸° (ê¸°ë³¸ê°’: true)",
                        "default": True
                    },
                    "skip_offset": {
                        "type": "integer",
                        "description": "HEADë¶€í„° ê±´ë„ˆë›¸ ì»¤ë°‹ ìˆ˜ (ê³¼ê±° ì»¤ë°‹ ì¶”ê°€ ì‹œ, ê¸°ë³¸ê°’: 0)",
                        "default": 0
                    }
                },
                "required": ["repo_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_index_statistics",
            "description": "ì¸ë±ìŠ¤ í†µê³„ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. ì´ ì»¤ë°‹ ìˆ˜, ì €ì¥ì†Œ ìˆ˜, ê¸°ì—¬ì ìˆ˜, ë‚ ì§œ ë²”ìœ„ ë“±ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": []
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "list_indexed_repositories",
            "description": "ì¸ë±ì‹±ëœ ì €ì¥ì†Œ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤. ê° ì €ì¥ì†Œì˜ ì»¤ë°‹ ìˆ˜ë„ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": []
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_repository_info",
            "description": "íŠ¹ì • ì €ì¥ì†Œì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. ì»¤ë°‹ ìˆ˜, ê¸°ì—¬ì ìˆ˜, ë‚ ì§œ ë²”ìœ„ ë“±ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "repo_id": {
                        "type": "string",
                        "description": "ì €ì¥ì†Œ ì‹ë³„ì (16ìë¦¬ í•´ì‹œ)"
                    }
                },
                "required": ["repo_id"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "delete_repository_commits",
            "description": "íŠ¹ì • ì €ì¥ì†Œì˜ ëª¨ë“  ì»¤ë°‹ì„ ì¸ë±ìŠ¤ì—ì„œ ì‚­ì œí•©ë‹ˆë‹¤. ì£¼ì˜: ë³µêµ¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "repo_id": {
                        "type": "string",
                        "description": "ì €ì¥ì†Œ ì‹ë³„ì (16ìë¦¬ í•´ì‹œ)"
                    }
                },
                "required": ["repo_id"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "check_index_health",
            "description": "ì¸ë±ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ì¸ë±ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {},
                "required": []
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_commits_by_date",
            "description": "ë‚ ì§œ ë²”ìœ„ë¡œ ì¸ë±ì‹±ëœ ì»¤ë°‹ì„ ì¡°íšŒí•©ë‹ˆë‹¤. íŠ¹ì • ê¸°ê°„ì˜ ì»¤ë°‹ í™œë™ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "since": {
                        "type": "string",
                        "description": "ì‹œì‘ ë‚ ì§œ (ISO 8601 í˜•ì‹, ì˜ˆ: 2024-01-01)"
                    },
                    "until": {
                        "type": "string",
                        "description": "ì¢…ë£Œ ë‚ ì§œ (ISO 8601 í˜•ì‹, ì˜ˆ: 2024-12-31)"
                    },
                    "repo_path": {
                        "type": "string",
                        "description": "íŠ¹ì • ì €ì¥ì†Œë§Œ ì¡°íšŒ (ì„ íƒì )"
                    },
                    "top": {
                        "type": "integer",
                        "description": "ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 50)",
                        "default": 50
                    }
                },
                "required": []
            }
        }
    }
]


def initialize_clients() -> tuple[AzureOpenAI, SearchClient, SearchIndexClient]:
    """Azure OpenAI, Search, IndexClient ì´ˆê¸°í™”"""
    try:
        openai_client = AzureOpenAI(
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-01"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
        )

        search_credential = AzureKeyCredential(os.getenv("AZURE_SEARCH_API_KEY"))

        search_client = SearchClient(
            endpoint=os.getenv("AZURE_SEARCH_ENDPOINT"),
            index_name=os.getenv("AZURE_SEARCH_INDEX_NAME"),
            credential=search_credential
        )

        index_client = SearchIndexClient(
            endpoint=os.getenv("AZURE_SEARCH_ENDPOINT"),
            credential=search_credential
        )

        logger.info("Clients initialized successfully")
        return openai_client, search_client, index_client

    except Exception as e:
        logger.error(f"Failed to initialize clients: {e}")
        raise


async def resolve_repository_ambiguity(
    repo_hint: str,
    search_client: SearchClient,
    index_client: SearchIndexClient
) -> Optional[str]:
    """ëª¨í˜¸í•œ ì €ì¥ì†Œ ì…ë ¥ì„ í•´ê²°í•˜ì—¬ ì •í™•í•œ ê²½ë¡œ ë°˜í™˜. ì‹¤íŒ¨ ì‹œ None ë°˜í™˜"""
    from src.index_manager import IndexManager

    index_manager = IndexManager(
        search_client=search_client,
        index_client=index_client,
        index_name=os.getenv("AZURE_SEARCH_INDEX_NAME", "git-commits")
    )

    # ì¸ë±ì‹±ëœ ëª¨ë“  ì €ì¥ì†Œ ê°€ì ¸ì˜¤ê¸°
    repos = index_manager.list_indexed_repositories()

    if not repos:
        return None

    # repo_hintë¡œ í•„í„°ë§ (ë¶€ë¶„ ì¼ì¹˜)
    matching_repos = [
        r for r in repos
        if repo_hint.lower() in r['repository_path'].lower()
    ]

    if len(matching_repos) == 0:
        return None
    elif len(matching_repos) == 1:
        return matching_repos[0]['repository_path']
    else:
        # ì—¬ëŸ¬ ê°œ ë°œê²¬ - ì‚¬ìš©ìì—ê²Œ ì„ íƒ ìš”ì²­
        options_text = "ğŸ” ì—¬ëŸ¬ ì €ì¥ì†Œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì„ íƒí•´ì£¼ì„¸ìš”:\n\n"
        for i, repo in enumerate(matching_repos, 1):
            options_text += f"{i}. {repo['repository_path']} ({repo['commit_count']}ê°œ ì»¤ë°‹)\n"
        options_text += f"\n1-{len(matching_repos)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”:"

        res = await cl.AskUserMessage(
            content=options_text,
            timeout=60,
            raise_on_timeout=False
        ).send()

        if not res or not res.get("output"):
            logger.info("User timeout or cancelled repository selection")
            return None

        try:
            choice = int(res.get("output").strip())
            if 1 <= choice <= len(matching_repos):
                selected = matching_repos[choice - 1]['repository_path']
                await cl.Message(content=f"âœ… ì„ íƒëœ ì €ì¥ì†Œ: `{selected}`").send()
                return selected
            else:
                await cl.Message(content=f"âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ë²ˆí˜¸ì…ë‹ˆë‹¤. 1-{len(matching_repos)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.").send()
                return None
        except ValueError:
            await cl.Message(content="âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.").send()
            return None


async def execute_tool(
    tool_name: str,
    arguments: Dict[str, Any],
    openai_client: AzureOpenAI,
    search_client: SearchClient,
    index_client: SearchIndexClient
) -> str:
    """ë„êµ¬ ì‹¤í–‰"""
    try:
        logger.info(f"Executing tool: {tool_name} with args: {arguments}")

        # repo_pathê°€ ì—†ê³  current_repositoryê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ìë™ ì ìš©
        current_repo = cl.user_session.get("current_repository")
        if "repo_path" in arguments and not arguments.get("repo_path") and current_repo:
            arguments["repo_path"] = current_repo
            logger.info(f"Using current repository: {current_repo}")
        elif "repo_path" not in arguments and current_repo and tool_name not in ["search_github_repo"]:
            arguments["repo_path"] = current_repo
            logger.info(f"Auto-applying current repository: {current_repo}")

        # ì €ì¥ì†Œ ê²½ë¡œ ëª¨í˜¸ì„± í•´ê²° (ì§§ì€ ì´ë¦„ì´ë‚˜ ë¶€ë¶„ ê²½ë¡œì¸ ê²½ìš°)
        if "repo_path" in arguments and arguments.get("repo_path"):
            repo_path = arguments["repo_path"]
            # ì ˆëŒ€ ê²½ë¡œê°€ ì•„ë‹ˆê³  ì§§ì€ ì´ë¦„ì¸ ê²½ìš° (ì˜ˆ: "project1", "myrepo")
            if not (repo_path.startswith("/") or repo_path.startswith("C:") or
                    repo_path.startswith("http://") or repo_path.startswith("https://")):
                logger.info(f"Ambiguous repository hint detected: {repo_path}")
                resolved_path = await resolve_repository_ambiguity(
                    repo_hint=repo_path,
                    search_client=search_client,
                    index_client=index_client
                )
                if resolved_path:
                    arguments["repo_path"] = resolved_path
                    logger.info(f"Resolved to: {resolved_path}")
                elif resolved_path is None:
                    return f"âŒ '{repo_path}'ì™€ ì¼ì¹˜í•˜ëŠ” ì¸ë±ì‹±ëœ ì €ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì •í™•í•œ ê²½ë¡œë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ë¨¼ì € ì €ì¥ì†Œë¥¼ ì¸ë±ì‹±í•´ì£¼ì„¸ìš”."

        # ì•ˆì „ ì¥ì¹˜: ìµœëŒ€ê°’ ì œí•œ ì ìš© (index_repositoryëŠ” ì œì™¸)
        # âš ï¸ index_repositoryì˜ limitì€ ì¦ë¶„ ì¸ë±ì‹± ë¡œì§ì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ê²½ê³ ë§Œ ë¡œê·¸
        if "limit" in arguments and arguments["limit"]:
            if tool_name == "index_repository":
                # index_repositoryëŠ” ê²½ê³ ë§Œ ë¡œê·¸, cap ì•ˆ í•¨
                if arguments["limit"] > MAX_COMMIT_LIMIT:
                    logger.warning(f"âš ï¸ Large limit requested: {arguments['limit']} (recommended max: {MAX_COMMIT_LIMIT})")
            else:
                # ë‹¤ë¥¸ ë„êµ¬ëŠ” cap ì ìš©
                if arguments["limit"] > MAX_COMMIT_LIMIT:
                    logger.warning(f"Limit {arguments['limit']} exceeds max {MAX_COMMIT_LIMIT}, capping")
                    arguments["limit"] = MAX_COMMIT_LIMIT

        if "top" in arguments and arguments["top"]:
            if arguments["top"] > MAX_SEARCH_TOP:
                logger.warning(f"Top {arguments['top']} exceeds max {MAX_SEARCH_TOP}, capping")
                arguments["top"] = MAX_SEARCH_TOP

        import asyncio
        loop = asyncio.get_event_loop()

        if tool_name == "get_commit_count":
            result = await loop.run_in_executor(
                None,
                lambda: get_commit_count(
                    repo_path=arguments["repo_path"],
                    since=arguments.get("since"),
                    until=arguments.get("until")
                )
            )
            return json.dumps(result, ensure_ascii=False, indent=2)

        elif tool_name == "get_commit_summary":
            result = await loop.run_in_executor(
                None,
                lambda: get_commit_summary(
                    repo_path=arguments["repo_path"],
                    llm_client=openai_client,
                    limit=arguments.get("limit", 50)
                )
            )
            return result

        elif tool_name == "search_commits":
            # ì €ì¥ì†Œ ê²½ë¡œê°€ ì§€ì •ëœ ê²½ìš° ìë™ ì¸ë±ì‹± í™•ì¸
            repo_path = arguments.get("repo_path")
            if repo_path:
                from src.indexer import normalize_repo_identifier
                repo_id = normalize_repo_identifier(repo_path)

                # í•´ë‹¹ ì €ì¥ì†Œê°€ ì¸ë±ì‹±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                try:
                    check_results = search_client.search(
                        search_text="*",
                        filter=f"repo_id eq '{repo_id}'",
                        select=["id"],
                        top=1
                    )
                    has_indexed = len(list(check_results)) > 0

                    if not has_indexed:
                        logger.info(f"Repository not indexed, asking user permission: {repo_path}")

                        # ì»¤ë°‹ ê°œìˆ˜ ë¨¼ì € í™•ì¸
                        commit_info = get_commit_count(repo_path)
                        total_commits = commit_info.get("commit_count", 0)
                        is_error = "error" in commit_info

                        if is_error:
                            commit_info_text = "**ì´ ì»¤ë°‹ ìˆ˜**: í™•ì¸ ë¶ˆê°€"
                        else:
                            commit_info_text = f"**ì´ ì»¤ë°‹ ìˆ˜**: {total_commits:,}ê°œ"

                        # ì‚¬ìš©ìì—ê²Œ ì¸ë±ì‹± í—ˆë½ ë°›ê¸° (UI ë²„íŠ¼)
                        res = await cl.AskActionMessage(
                            content=f"ğŸ” ê²€ìƒ‰ì„ ìœ„í•´ ì €ì¥ì†Œë¥¼ ì¸ë±ì‹±í•´ì•¼ í•©ë‹ˆë‹¤.\n\n**ì €ì¥ì†Œ**: `{repo_path}`\n{commit_info_text}\n**ì¸ë±ì‹± ì˜ˆì •**: ìµœê·¼ {DEFAULT_INDEX_LIMIT}ê°œ ì»¤ë°‹\n\nì¸ë±ì‹±ì„ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                            actions=[
                                cl.Action(name="yes", payload={"action": "yes"}, label="âœ… ì˜ˆ, ì¸ë±ì‹± ì‹œì‘"),
                                cl.Action(name="no", payload={"action": "no"}, label="âŒ ì•„ë‹ˆì˜¤, ì·¨ì†Œ"),
                            ],
                            timeout=120,  # 2ë¶„
                            raise_on_timeout=False
                        ).send()

                        if not res:
                            logger.info(f"User timeout for indexing: {repo_path}")
                            return "â±ï¸ ì‹œê°„ ì´ˆê³¼. ì¸ë±ì‹±ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ë ¤ë©´ ê²€ìƒ‰ì„ ë‹¤ì‹œ ìš”ì²­í•´ì£¼ì„¸ìš”."

                        if res.get("payload", {}).get("action") == "yes":
                            # ì¸ë±ì‹± ì‹œì‘ ì•Œë¦¼
                            await cl.Message(content="â³ ì¸ë±ì‹±ì„ ì‹œì‘í•©ë‹ˆë‹¤...").send()

                            # ìë™ ì¸ë±ì‹± ì‹¤í–‰
                            indexer = CommitIndexer(
                                search_client=search_client,
                                index_client=index_client,
                                openai_client=openai_client,
                                index_name=os.getenv("AZURE_SEARCH_INDEX_NAME", "git-commits")
                            )
                            indexer.create_index_if_not_exists()

                            indexed_count = indexer.index_repository(
                                repo_path=repo_path,
                                limit=DEFAULT_INDEX_LIMIT,
                                skip_existing=True
                            )

                            logger.info(f"User approved, indexed {indexed_count} commits for {repo_path}")

                            # ì¸ë±ì‹± ì™„ë£Œ ë©”ì‹œì§€ (Step ì™¸ë¶€ì— ëª…í™•íˆ í‘œì‹œ)
                            if indexed_count == 0:
                                await cl.Message(content="âœ… **ì¸ë±ì‹± ì™„ë£Œ**\n\nì €ì¥ì†Œê°€ ì´ë¯¸ ì¸ë±ì‹±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ì„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.").send()
                                # ê²€ìƒ‰ì„ ê³„ì† ì§„í–‰í•˜ë„ë¡ pass through
                            else:
                                await cl.Message(content=f"âœ… **ì¸ë±ì‹± ì™„ë£Œ**\n\n{indexed_count}ê°œ ì»¤ë°‹ì´ ì¸ë±ì‹±ë˜ì—ˆìŠµë‹ˆë‹¤.\nê²€ìƒ‰ì„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...").send()
                                # ê²€ìƒ‰ì„ ê³„ì† ì§„í–‰í•˜ë„ë¡ pass through
                        else:
                            logger.info(f"User declined indexing for {repo_path}")
                            return "âŒ ì‚¬ìš©ìê°€ ì¸ë±ì‹±ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

                except Exception as e:
                    logger.warning(f"Failed to check indexing status: {e}")

            # ê²€ìƒ‰ ì‹¤í–‰
            results = await loop.run_in_executor(
                None,
                lambda: search_commits(
                    query=arguments["query"],
                    search_client=search_client,
                    openai_client=openai_client,
                    top=arguments.get("top", 10),
                    repo_path=repo_path
                )
            )

            # ê²°ê³¼ ìš”ì•½ (í˜ì´ë¡œë“œ í¬ê¸° ì œí•œ)
            if isinstance(results, list) and len(results) > 0:
                summary = f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ì»¤ë°‹ ë°œê²¬\n\n"
                for i, r in enumerate(results[:10], 1):  # ìµœëŒ€ 10ê°œë§Œ
                    commit_id = r.get('commit_id', 'N/A')
                    short_sha = commit_id[:8] if len(commit_id) >= 8 else commit_id
                    summary += f"{i}. [{short_sha}] {r.get('message', 'N/A')[:80]}... (by {r.get('author', 'N/A')})\n"
                if len(results) > 10:
                    summary += f"\n...ì™¸ {len(results)-10}ê°œ ì»¤ë°‹"
                return summary
            return json.dumps(results, ensure_ascii=False, indent=2)

        elif tool_name == "analyze_contributors":
            # limit ê¸°ë³¸ê°’ ì„¤ì • (ì—†ìœ¼ë©´ 500ìœ¼ë¡œ ì œí•œ)
            contributor_limit = arguments.get("limit", 500)
            if contributor_limit > MAX_CONTRIBUTOR_LIMIT:
                contributor_limit = MAX_CONTRIBUTOR_LIMIT

            result = await loop.run_in_executor(
                None,
                lambda: analyze_contributors(
                    repo_path=arguments["repo_path"],
                    criteria=arguments.get("criteria"),
                    limit=contributor_limit,
                    since=arguments.get("since"),
                    until=arguments.get("until")
                )
            )

            # ê²°ê³¼ ìš”ì•½
            if isinstance(result, dict) and 'contributors' in result:
                contributors = result['contributors']
                date_info = ""
                if arguments.get("since") or arguments.get("until"):
                    date_parts = []
                    if arguments.get("since"):
                        date_parts.append(f"{arguments['since']} ì´í›„")
                    if arguments.get("until"):
                        date_parts.append(f"{arguments['until']} ì´ì „")
                    date_info = f" ({', '.join(date_parts)})"
                summary = f"ğŸ‘¥ ê¸°ì—¬ì ë¶„ì„ ê²°ê³¼{date_info}: ì´ {len(contributors)}ëª…\n\n"
                for i, c in enumerate(contributors[:10], 1):  # ìµœëŒ€ 10ëª…
                    summary += f"{i}. {c.get('name', 'N/A')}: {c.get('commits', 0)}ê°œ ì»¤ë°‹, {c.get('total_lines_changed', 0)}ì¤„ ë³€ê²½\n"
                if len(contributors) > 10:
                    summary += f"\n...ì™¸ {len(contributors)-10}ëª…"
                return summary
            return json.dumps(result, ensure_ascii=False, indent=2)

        elif tool_name == "find_bug_commits":
            results = await loop.run_in_executor(
                None,
                lambda: find_frequent_bug_commits(
                    repo_path=arguments["repo_path"],
                    llm_client=openai_client,
                    limit=arguments.get("limit", 200)
                )
            )

            # ê²°ê³¼ ìš”ì•½
            if isinstance(results, list) and len(results) > 0:
                summary = f"ğŸ› ë²„ê·¸ ìˆ˜ì • ì»¤ë°‹: {len(results)}ê°œ ë°œê²¬\n\n"
                for i, r in enumerate(results[:10], 1):  # ìµœëŒ€ 10ê°œ
                    summary += f"{i}. {r.get('message', 'N/A')[:80]}... (by {r.get('author', 'N/A')})\n"
                if len(results) > 10:
                    summary += f"\n...ì™¸ {len(results)-10}ê°œ ì»¤ë°‹"
                return summary
            return json.dumps(results, ensure_ascii=False, indent=2)

        elif tool_name == "search_github_repo":
            reader = OnlineRepoReader()
            results = await loop.run_in_executor(
                None,
                lambda: reader.search_github_repo(
                    query=arguments["query"],
                    max_results=arguments.get("max_results", 5)
                )
            )

            # ê²°ê³¼ ìš”ì•½ (í˜ì´ë¡œë“œ í¬ê¸° ì œí•œ)
            if results and len(results) > 0:
                summary = f"ğŸ” GitHub ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ì €ì¥ì†Œ\n\n"
                for i, repo in enumerate(results, 1):
                    desc = repo.get('description', 'No description')
                    if len(desc) > 100:
                        desc = desc[:100] + "..."

                    summary += f"{i}. **{repo.get('full_name', 'N/A')}** â­ {repo.get('stars', 0):,}\n"
                    summary += f"   ì–¸ì–´: {repo.get('language', 'N/A')} | {desc}\n"
                    summary += f"   URL: {repo.get('url', 'N/A')}\n\n"

                return summary
            elif results is None:
                return "GitHub ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            else:
                return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        elif tool_name == "read_file_from_commit":
            content = await loop.run_in_executor(
                None,
                lambda: read_file_from_commit(
                    repo_path=arguments["repo_path"],
                    commit_sha=arguments["commit_sha"],
                    file_path=arguments["file_path"]
                )
            )
            return content if content else "íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        elif tool_name == "get_file_context":
            context = await loop.run_in_executor(
                None,
                lambda: get_file_context(
                    repo_path=arguments["repo_path"],
                    commit_sha=arguments["commit_sha"],
                    file_path=arguments["file_path"]
                )
            )

            # ê²°ê³¼ ìš”ì•½
            if context:
                summary = f"ğŸ“„ íŒŒì¼ ì»¨í…ìŠ¤íŠ¸: {context.get('file_path', 'N/A')}\n"
                summary += f"ì»¤ë°‹: {context.get('commit_sha', 'N/A')[:8]}\n"
                summary += f"ë³€ê²½ íƒ€ì…: {context.get('change_type', 'N/A')}\n"

                if context.get('diff'):
                    diff_text = context['diff']
                    if len(diff_text) > 1000:
                        diff_text = diff_text[:1000] + "\n...(truncated)"
                    summary += f"\nDiff:\n```\n{diff_text}\n```"

                return summary
            else:
                return "íŒŒì¼ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        elif tool_name == "get_commit_diff":
            diff_info = await loop.run_in_executor(
                None,
                lambda: get_commit_diff(
                    repo_path=arguments["repo_path"],
                    commit_sha=arguments["commit_sha"],
                    max_files=arguments.get("max_files", 10)
                )
            )

            if diff_info:
                # ì—ëŸ¬ì¸ ê²½ìš°
                if diff_info.get("error"):
                    return diff_info["message"]

                # ì •ìƒì¸ ê²½ìš° - ìš”ì•½í•´ì„œ ì „ë‹¬
                summary = f"ğŸ“ ì»¤ë°‹ Diff: {diff_info.get('short_sha', 'N/A')}\n"
                summary += f"ì‘ì„±ì: {diff_info.get('author', 'N/A')}\n"
                summary += f"ë‚ ì§œ: {diff_info.get('date', 'N/A')}\n"
                summary += f"ë©”ì‹œì§€: {diff_info.get('message', 'N/A')[:200]}\n\n"

                stats = diff_info.get('stats', {})
                summary += f"ğŸ“Š í†µê³„: {stats.get('files', 0)}ê°œ íŒŒì¼, "
                summary += f"+{stats.get('insertions', 0)}/-{stats.get('deletions', 0)} ë¼ì¸\n\n"

                files_changed = diff_info.get('files_changed', [])
                if files_changed:
                    summary += f"ğŸ“‚ ë³€ê²½ëœ íŒŒì¼ ({len(files_changed)}ê°œ):\n"
                    for i, f in enumerate(files_changed[:5], 1):  # ìµœëŒ€ 5ê°œë§Œ
                        summary += f"{i}. {f.get('file', 'N/A')} "
                        summary += f"(+{f.get('lines_added', 0)}/-{f.get('lines_deleted', 0)})\n"

                        # diff ë‚´ìš© ì¼ë¶€ë§Œ
                        if f.get('diff') and len(f['diff']) > 0:
                            diff_preview = f['diff'][:500]
                            if len(f['diff']) > 500:
                                diff_preview += "\n...(truncated)"
                            summary += f"```diff\n{diff_preview}\n```\n"

                    if len(files_changed) > 5:
                        summary += f"\n...ì™¸ {len(files_changed) - 5}ê°œ íŒŒì¼"

                return summary
            else:
                return "ì»¤ë°‹ diffë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        elif tool_name == "get_readme":
            content = await loop.run_in_executor(
                None,
                lambda: get_readme_content(arguments["repo_path"])
            )
            return content if content else "README íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        elif tool_name == "set_current_repository":
            repo_path = arguments["repo_path"]
            cl.user_session.set("current_repository", repo_path)
            logger.info(f"Current repository set to: {repo_path}")
            return f"í˜„ì¬ ì €ì¥ì†Œë¥¼ '{repo_path}'ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤. ì´ì œ ì €ì¥ì†Œ ê²½ë¡œë¥¼ ìƒëµí•˜ë©´ ì´ ì €ì¥ì†Œê°€ ì‚¬ìš©ë©ë‹ˆë‹¤."

        elif tool_name == "index_repository":
            indexer = CommitIndexer(
                search_client=search_client,
                index_client=index_client,
                openai_client=openai_client,
                index_name=os.getenv("AZURE_SEARCH_INDEX_NAME", "git-commits")
            )

            # ì¸ë±ìŠ¤ ìƒì„± (ì—†ìœ¼ë©´)
            indexer.create_index_if_not_exists()

            # âš ï¸ ì¦ë¶„ ì¸ë±ì‹± ë¡œì§ - capë˜ì§€ ì•Šì€ ì›ë˜ limit ê°’ ì‚¬ìš©
            skip_offset = arguments.get("skip_offset", 0)
            original_limit = arguments.get("limit")  # âœ… cap ì´ì „ì˜ ì›ë˜ ê°’

            # âš ï¸ ì¦ë¶„ ì¸ë±ì‹± ì¡°ê±´:
            # 1. skip_offsetì´ ëª…ì‹œë˜ì§€ ì•ŠìŒ (0)
            # 2. ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ limitì„ ìš”ì²­í•¨
            # 3. skip_existing=True (ê¸°ë³¸ê°’)
            # 4. ë‚ ì§œ ë²”ìœ„ê°€ ì—†ìŒ (ë‚ ì§œ ë²”ìœ„ê°€ ìˆìœ¼ë©´ ì¦ë¶„ ì¸ë±ì‹± ë¶ˆê°€)
            should_apply_incremental = (
                skip_offset == 0 and
                original_limit is not None and
                arguments.get("skip_existing", True) and
                not arguments.get("since") and
                not arguments.get("until")
            )

            if should_apply_incremental:
                try:
                    from src.indexer import normalize_repo_identifier
                    repo_id = normalize_repo_identifier(arguments["repo_path"])

                    # ê¸°ì¡´ ì¸ë±ì‹± ê°œìˆ˜ í™•ì¸
                    check_results = search_client.search(
                        search_text="*",
                        filter=f"repo_id eq '{repo_id}'",
                        select=["id"],
                        top=10000
                    )
                    existing_count = len(list(check_results))

                    if existing_count > 0:
                        logger.info(f"Found {existing_count} existing commits, user requested {original_limit} total")

                        if original_limit > existing_count:
                            # ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì´ ê°œìˆ˜ì—ì„œ ì´ë¯¸ ìˆëŠ” ê°œìˆ˜ë¥¼ ë¹¼ì„œ ì‹¤ì œ í•„ìš”í•œ ê°œìˆ˜ ê³„ì‚°
                            adjusted_limit = original_limit - existing_count
                            logger.info(f"Adjusting limit: {original_limit} (total requested) - {existing_count} (existing) = {adjusted_limit} (additional needed)")

                            # skip_offsetê³¼ limit ëª¨ë‘ ì¡°ì •
                            skip_offset = existing_count
                            arguments["skip_offset"] = skip_offset
                            arguments["limit"] = adjusted_limit

                        elif original_limit <= existing_count:
                            # ì´ë¯¸ ì¶©ë¶„í•œ ì»¤ë°‹ì´ ìˆìŒ
                            logger.info(f"Already have {existing_count} commits (>= {original_limit} requested) - no additional indexing needed")
                            # ì¸ë±ì‹±ì„ ê±´ë„ˆë›°ê³  ë°”ë¡œ ì™„ë£Œ ë©”ì‹œì§€ ë°˜í™˜
                            return f"âœ… ì €ì¥ì†Œì— ì´ë¯¸ {existing_count:,}ê°œ ì»¤ë°‹ì´ ì¸ë±ì‹±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. (ìš”ì²­: {original_limit:,}ê°œ)\nì¶”ê°€ ì¸ë±ì‹±ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

                except Exception as e:
                    logger.warning(f"Failed to calculate incremental indexing: {e}")

            # âœ… ì¦ë¶„ ì¸ë±ì‹± ê³„ì‚° ì™„ë£Œ í›„ limit ì„¤ì •
            # limitì´ ì—†ìœ¼ë©´ DEFAULT_INDEX_LIMIT ì‚¬ìš©
            index_limit = arguments.get("limit")
            if index_limit is None:
                logger.warning(f"No limit specified for indexing, defaulting to {DEFAULT_INDEX_LIMIT}")
                index_limit = DEFAULT_INDEX_LIMIT

            # âš ï¸ MAX_COMMIT_LIMITì€ ê¶Œì¥ ì‚¬í•­ì¼ ë¿, ê°•ì œí•˜ì§€ ì•ŠìŒ (ì¦ë¶„ ì¸ë±ì‹± ì§€ì›)
            if index_limit > MAX_COMMIT_LIMIT:
                logger.warning(f"âš ï¸ Large indexing: {index_limit} commits (recommended max: {MAX_COMMIT_LIMIT})")

            # ëŒ€ìš©ëŸ‰ ì¸ë±ì‹±(DEFAULT_INDEX_LIMITê°œ ì´ìƒ)ì´ë©´ ì‚¬ìš©ì í™•ì¸
            if index_limit >= DEFAULT_INDEX_LIMIT:
                since_param = arguments.get("since", "")
                until_param = arguments.get("until", "")
                date_info = ""
                if since_param or until_param:
                    date_info = f"\n**ë‚ ì§œ ë²”ìœ„**: {since_param or 'ì‹œì‘'} ~ {until_param or 'ë'}"

                # ğŸ“Š ì „ì²´ ì»¤ë°‹ ìˆ˜ë¥¼ í™•ì¸ (UIì— í‘œì‹œí•˜ê¸° ìœ„í•´)
                commit_info_msg = await cl.Message(content="ğŸ“Š ì €ì¥ì†Œ ì»¤ë°‹ ìˆ˜ë¥¼ í™•ì¸í•˜ëŠ” ì¤‘...").send()
                try:
                    total_commit_info = await loop.run_in_executor(
                        None,
                        lambda: get_commit_count(
                            repo_path=arguments["repo_path"],
                            since=since_param or None,
                            until=until_param or None
                        )
                    )
                    total_commits = total_commit_info.get("commit_count", 0)
                    commit_info_msg.content = f"ğŸ“Š ì „ì²´ ì»¤ë°‹ ìˆ˜: **{total_commits:,}ê°œ**"
                    await commit_info_msg.update()
                except Exception as e:
                    logger.warning(f"Failed to get total commit count: {e}")
                    total_commits = None
                    commit_info_msg.content = f"âš ï¸ ì „ì²´ ì»¤ë°‹ ìˆ˜ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    await commit_info_msg.update()

                # UI ë©”ì‹œì§€ ì¤€ë¹„
                ui_content = f"âš ï¸ ëŒ€ìš©ëŸ‰ ì¸ë±ì‹± ìš”ì²­\n\n**ì €ì¥ì†Œ**: {arguments['repo_path']}\n"
                if total_commits is not None:
                    ui_content += f"**ì „ì²´ ì»¤ë°‹ ìˆ˜**: {total_commits:,}ê°œ\n"
                ui_content += f"**ì¸ë±ì‹± ì˜ˆì •**: {index_limit}ê°œ ì»¤ë°‹{date_info}\n\nì§„í–‰ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:"

                # ì‚¬ìš©ì í™•ì¸ ëŒ€ê¸° ë©”ì‹œì§€ (Step ì™¸ë¶€ì— í‘œì‹œ)
                await cl.Message(content="â¸ï¸ ì‚¬ìš©ì í™•ì¸ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ì…ë‹ˆë‹¤...").send()

                res = await cl.AskActionMessage(
                    content=ui_content,
                    actions=[
                        cl.Action(name="proceed", payload={"action": "proceed"}, label="âœ… ê·¸ëŒ€ë¡œ ì§„í–‰"),
                        cl.Action(name="custom", payload={"action": "custom", "total_commits": total_commits}, label="âœï¸ ê°œìˆ˜/ë‚ ì§œ ë³€ê²½"),
                        cl.Action(name="cancel", payload={"action": "cancel"}, label="âŒ ì·¨ì†Œ"),
                    ],
                    timeout=120,  # 2ë¶„
                    raise_on_timeout=False
                ).send()

                if not res:
                    logger.info(f"User timeout for large indexing: {index_limit} commits")
                    return f"âŒ ì‹œê°„ ì´ˆê³¼. ì¸ë±ì‹±ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤."

                action = res.get("payload", {}).get("action")

                if action == "proceed":
                    await cl.Message(content=f"âœ… ì‚¬ìš©ì ìŠ¹ì¸ë¨. {index_limit}ê°œ ì»¤ë°‹ ì¸ë±ì‹±ì„ ì‹œì‘í•©ë‹ˆë‹¤...").send()

                elif action == "custom":
                    # ì „ì²´ ì»¤ë°‹ ìˆ˜ ì •ë³´ë¥¼ UIì— í‘œì‹œ
                    total_commits_from_payload = res.get("payload", {}).get("total_commits")
                    total_info_text = ""
                    if total_commits_from_payload is not None and total_commits_from_payload > 0:
                        total_info_text = f"\n\n**ì „ì²´ ì»¤ë°‹ ìˆ˜**: {total_commits_from_payload:,}ê°œ (ì „ì²´ ì¸ë±ì‹±ì„ ì›í•˜ì‹œë©´ ì´ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”)"

                    # ì‚¬ìš©ì ì •ì˜ ê°œìˆ˜ ì…ë ¥ ë°›ê¸°
                    custom_limit_res = await cl.AskUserMessage(
                        content=f"ğŸ“ ì¸ë±ì‹±í•  ì»¤ë°‹ ê°œìˆ˜ ë˜ëŠ” ë²”ìœ„ë¥¼ ì…ë ¥í•˜ì„¸ìš”:\n\n"
                                f"â€¢ **ìˆ«ì**: ì˜ˆ) 500, 1000\n"
                                f"â€¢ **í‚¤ì›Œë“œ**: 'ì „ì²´', 'ì˜¬í•´', 'ìµœê·¼'\n"
                                f"â€¢ **ë‚ ì§œ**: 2025-01-01 ë˜ëŠ” 2025-01-01,2025-12-31\n\n"
                                f"ì „ì²´ ì»¤ë°‹ ìˆ˜: {total_commits_from_payload:,}ê°œ\n"
                                f"âš ï¸ {MAX_COMMIT_LIMIT}ê°œ ì´ìƒì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                        timeout=60,
                        raise_on_timeout=False
                    ).send()

                    if not custom_limit_res or not custom_limit_res.get("output"):
                        return "â±ï¸ ì‹œê°„ ì´ˆê³¼ ë˜ëŠ” ì…ë ¥ ì—†ìŒ. ì¸ë±ì‹±ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤."

                    try:
                        user_input = custom_limit_res.get("output").strip().lower()
                        import re
                        from datetime import datetime

                        # ğŸ” í‚¤ì›Œë“œ ì²˜ë¦¬
                        if any(keyword in user_input for keyword in ['ì „ì²´', 'ëª¨ë‘', 'all']):
                            # ì „ì²´ ì»¤ë°‹
                            index_limit = total_commits_from_payload if total_commits_from_payload else None
                            logger.info(f"User requested 'all': {index_limit}")
                            arguments["limit"] = index_limit

                        elif any(keyword in user_input for keyword in ['ì˜¬í•´', '2025', 'this year']):
                            # ì˜¬í•´ ì»¤ë°‹
                            arguments["since"] = "2025-01-01"
                            arguments["until"] = "2025-12-31"
                            index_limit = None  # ë‚ ì§œ ë²”ìœ„ë¡œ ì œí•œ
                            logger.info("User requested 'this year': 2025-01-01 ~ 2025-12-31")
                            await cl.Message(content="ğŸ“… ì˜¬í•´(2025ë…„) ì»¤ë°‹ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.").send()

                        elif any(keyword in user_input for keyword in ['ìµœê·¼', 'recent']):
                            # ìµœê·¼ 500ê°œ
                            index_limit = 500
                            logger.info("User requested 'recent': 500")
                            arguments["limit"] = index_limit

                        elif ',' in user_input or re.match(r'\d{4}-\d{2}-\d{2}', user_input):
                            # ë‚ ì§œ ë²”ìœ„ í˜•ì‹
                            if ',' in user_input:
                                parts = user_input.split(',')
                                if len(parts) == 2:
                                    arguments["since"] = parts[0].strip()
                                    arguments["until"] = parts[1].strip()
                                    index_limit = None
                                    logger.info(f"User provided date range: {parts[0]} ~ {parts[1]}")
                                    await cl.Message(content=f"ğŸ“… ë‚ ì§œ ë²”ìœ„: {parts[0]} ~ {parts[1]}").send()
                            else:
                                # ë‹¨ì¼ ë‚ ì§œ (sinceë§Œ)
                                arguments["since"] = user_input.strip()
                                index_limit = None
                                logger.info(f"User provided start date: {user_input}")
                                await cl.Message(content=f"ğŸ“… ì‹œì‘ì¼: {user_input}").send()
                        else:
                            # ìˆ«ì ì¶”ì¶œ
                            numeric_input = re.sub(r'[^\d]', '', user_input)

                            if not numeric_input:
                                return "âŒ ìœ íš¨í•œ ìˆ«ì, í‚¤ì›Œë“œ, ë˜ëŠ” ë‚ ì§œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\nì˜ˆ: 500, 'ì˜¬í•´', 2025-01-01"

                            custom_limit = int(numeric_input)

                            if custom_limit < 1:
                                return "âŒ 1ê°œ ì´ìƒì˜ ì»¤ë°‹ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."

                            index_limit = custom_limit
                            logger.info(f"User selected custom limit: {index_limit}")
                            arguments["limit"] = index_limit

                    except Exception as e:
                        logger.error(f"Error parsing user input: {e}")
                        return f"âŒ ì…ë ¥ í˜•ì‹ ì˜¤ë¥˜: {str(e)}\nì˜ˆ: 500, 'ì˜¬í•´', 2025-01-01,2025-12-31"

                    # ë‚ ì§œ ë²”ìœ„ ì…ë ¥ ë°›ê¸° (ì´ë¯¸ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°ë§Œ)
                    if not arguments.get("since") and not arguments.get("until"):
                        date_res = await cl.AskUserMessage(
                            content="ğŸ“… ë‚ ì§œ ë²”ìœ„ë¥¼ ì…ë ¥í•˜ì„¸ìš” (í˜•ì‹: YYYY-MM-DD,YYYY-MM-DD ë˜ëŠ” ë¹ˆì¹¸ìœ¼ë¡œ ê±´ë„ˆë›°ê¸°):\n\nì˜ˆ: 2024-01-01,2024-12-31",
                            timeout=60,
                            raise_on_timeout=False
                        ).send()

                        if date_res and date_res.get("output") and date_res.get("output").strip():
                            date_input = date_res.get("output").strip()
                            if "," in date_input:
                                parts = date_input.split(",")
                                if len(parts) == 2:
                                    arguments["since"] = parts[0].strip() or None
                                    arguments["until"] = parts[1].strip() or None

                    await cl.Message(content=f"âœ… ì„¤ì • ì™„ë£Œ. {index_limit:,}ê°œ ì»¤ë°‹ ì¸ë±ì‹±ì„ ì‹œì‘í•©ë‹ˆë‹¤...").send()

                else:  # cancel
                    logger.info(f"User declined large indexing: {index_limit} commits")
                    return f"âŒ ì‚¬ìš©ìê°€ ëŒ€ìš©ëŸ‰ ì¸ë±ì‹±ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤. ë” ì‘ì€ ë²”ìœ„ë¡œ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ë‚ ì§œ ë²”ìœ„ë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”."

            # ì¼ë°˜ ì¸ë±ì‹± (ë¶„í•  ì—†ì´ í•œ ë²ˆì— ì²˜ë¦¬)
            # âš ï¸ MAX_COMMIT_LIMITì€ ê¶Œì¥ ì‚¬í•­ì¼ ë¿, ì¦ë¶„ ì¸ë±ì‹±ì€ ì „ì²´ë¥¼ ì²˜ë¦¬í•´ì•¼ í•¨
            indexed_count = await loop.run_in_executor(
                None,
                lambda: indexer.index_repository(
                    repo_path=arguments["repo_path"],
                    limit=index_limit,
                    since=arguments.get("since"),
                    until=arguments.get("until"),
                    skip_existing=arguments.get("skip_existing", True),
                    skip_offset=arguments.get("skip_offset", 0)
                )
            )

            # ì¸ë±ì‹± ì™„ë£Œ ë©”ì‹œì§€ë¥¼ Step ì™¸ë¶€ì— ëª…í™•íˆ í‘œì‹œ
            if indexed_count == 0:
                logger.info(f"Repository already indexed: {arguments['repo_path']}")
                await cl.Message(content=f"âœ… **ì¸ë±ì‹± í™•ì¸ ì™„ë£Œ**\n\nì €ì¥ì†Œê°€ ì´ë¯¸ ì¸ë±ì‹±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\nì €ì¥ì†Œ: `{arguments['repo_path']}`").send()
                return f"ì €ì¥ì†Œê°€ ì´ë¯¸ ì¸ë±ì‹±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ ë° ë¶„ì„ì„ ë°”ë¡œ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            else:
                # ì „ì²´ ì¸ë±ì‹± í˜„í™© í™•ì¸ (ì¦ë¶„ ì¸ë±ì‹± ì»¨í…ìŠ¤íŠ¸ ì œê³µ)
                try:
                    from src.indexer import normalize_repo_identifier
                    repo_id = normalize_repo_identifier(arguments["repo_path"])

                    # í˜„ì¬ ì¸ë±ì‹±ëœ ì´ ê°œìˆ˜ í™•ì¸
                    total_check_results = search_client.search(
                        search_text="*",
                        filter=f"repo_id eq '{repo_id}'",
                        select=["id"],
                        top=10000
                    )
                    total_indexed_count = len(list(total_check_results))

                    result_msg = f"{indexed_count}ê°œ ì»¤ë°‹ì´ ìƒˆë¡œ ì¸ë±ì‹±ë˜ì—ˆìŠµë‹ˆë‹¤. (ì „ì²´: {total_indexed_count}ê°œ)"
                except Exception as e:
                    logger.warning(f"Failed to get total indexed count: {e}")
                    result_msg = f"{indexed_count}ê°œ ì»¤ë°‹ì´ ì¸ë±ì‹±ë˜ì—ˆìŠµë‹ˆë‹¤."

                if arguments.get("since") or arguments.get("until"):
                    # ë‚ ì§œ ë²”ìœ„ ì¸ë±ì‹±ì˜ ê²½ìš° ì‹¤ì œ ì¸ë±ì‹±ëœ ë‚ ì§œ ë²”ìœ„ í™•ì¸
                    try:
                        from src.indexer import normalize_repo_identifier
                        repo_id = normalize_repo_identifier(arguments["repo_path"])

                        # ì¸ë±ì‹±ëœ ì‹¤ì œ ë‚ ì§œ ë²”ìœ„ ì¡°íšŒ
                        date_check_results = search_client.search(
                            search_text="*",
                            filter=f"repo_id eq '{repo_id}'",
                            select=["date"],
                            order_by=["date asc"],
                            top=1
                        )
                        oldest_result = list(date_check_results)

                        date_check_results = search_client.search(
                            search_text="*",
                            filter=f"repo_id eq '{repo_id}'",
                            select=["date"],
                            order_by=["date desc"],
                            top=1
                        )
                        newest_result = list(date_check_results)

                        if oldest_result and newest_result:
                            oldest_date = oldest_result[0]["date"][:10]  # YYYY-MM-DDë§Œ
                            newest_date = newest_result[0]["date"][:10]

                            requested_range = f"{arguments.get('since', 'ì‹œì‘')} ~ {arguments.get('until', 'ë')}"
                            actual_range = f"{oldest_date} ~ {newest_date}"

                            result_msg += f"\n\n**ë‚ ì§œ ë²”ìœ„ ê²€ì¦**:\n"
                            result_msg += f"- ìš”ì²­í•œ ë²”ìœ„: {requested_range}\n"
                            result_msg += f"- ì‹¤ì œ ì¸ë±ì‹±ëœ ë²”ìœ„: {actual_range}\n"

                            # ìš”ì²­ ë²”ìœ„ì™€ ì‹¤ì œ ë²”ìœ„ê°€ ë‹¤ë¥¸ ê²½ìš° ì•ˆë‚´
                            if arguments.get("since") and arguments.get("since") != oldest_date:
                                result_msg += f"- âš ï¸ ìš”ì²­í•œ ì‹œì‘ì¼({arguments.get('since')})ì—ëŠ” ì»¤ë°‹ì´ ì—†ì–´ì„œ {oldest_date}ë¶€í„° ì‹œì‘ë¨\n"
                            if arguments.get("until") and arguments.get("until") != newest_date:
                                result_msg += f"- âš ï¸ ìš”ì²­í•œ ì¢…ë£Œì¼({arguments.get('until')})ì—ëŠ” ì»¤ë°‹ì´ ì—†ì–´ì„œ {newest_date}ê¹Œì§€ë§Œ í¬í•¨ë¨\n"

                    except Exception as e:
                        logger.warning(f"Failed to verify date range: {e}")

                await cl.Message(content=f"âœ… **ì¸ë±ì‹± ì™„ë£Œ**\n\n{result_msg}\n\nì €ì¥ì†Œ: `{arguments['repo_path']}`").send()
                return result_msg

        elif tool_name == "get_index_statistics":
            index_manager = IndexManager(
                search_client=search_client,
                index_client=index_client,
                index_name=os.getenv("AZURE_SEARCH_INDEX_NAME", "git-commits")
            )
            stats = await loop.run_in_executor(
                None,
                lambda: index_manager.get_index_statistics()
            )
            formatted = format_index_statistics(stats)
            return formatted

        elif tool_name == "list_indexed_repositories":
            index_manager = IndexManager(
                search_client=search_client,
                index_client=index_client,
                index_name=os.getenv("AZURE_SEARCH_INDEX_NAME", "git-commits")
            )
            repos = await loop.run_in_executor(
                None,
                lambda: index_manager.list_indexed_repositories()
            )

            if not repos:
                return "ì¸ë±ì‹±ëœ ì €ì¥ì†Œê°€ ì—†ìŠµë‹ˆë‹¤."

            result_lines = ["ğŸ“ **ì¸ë±ì‹±ëœ ì €ì¥ì†Œ ëª©ë¡**", ""]
            for repo in repos:
                result_lines.append(
                    f"- **{repo['repository_path']}**\n"
                    f"  - Repo ID: `{repo['repo_id']}`\n"
                    f"  - ì»¤ë°‹ ìˆ˜: {repo['commit_count']}"
                )

            return "\n".join(result_lines)

        elif tool_name == "get_repository_info":
            index_manager = IndexManager(
                search_client=search_client,
                index_client=index_client,
                index_name=os.getenv("AZURE_SEARCH_INDEX_NAME", "git-commits")
            )
            info = await loop.run_in_executor(
                None,
                lambda: index_manager.get_repository_info(arguments["repo_id"])
            )

            if not info:
                return f"ì €ì¥ì†Œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {arguments['repo_id']}"

            # êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ê²°ê³¼ ìƒì„±
            result_parts = [
                "ğŸ“Š **ì €ì¥ì†Œ ì •ë³´**",
                "",
                f"**ê²½ë¡œ**: {info['repository_path']}",
                f"**Repo ID**: `{info['repo_id']}`",
                f"**ì»¤ë°‹ ìˆ˜**: {info['commit_count']:,}",
                f"**ê¸°ì—¬ì ìˆ˜**: {info['author_count']}",
                "",
                "**ë‚ ì§œ ë²”ìœ„**:",
                f"- ê°€ì¥ ì˜¤ë˜ëœ ì»¤ë°‹: {info['date_range']['oldest'] or 'N/A'}",
                f"- ê°€ì¥ ìµœê·¼ ì»¤ë°‹: {info['date_range']['newest'] or 'N/A'}"
            ]
            return "\n".join(result_parts)

        elif tool_name == "delete_repository_commits":
            index_manager = IndexManager(
                search_client=search_client,
                index_client=index_client,
                index_name=os.getenv("AZURE_SEARCH_INDEX_NAME", "git-commits")
            )
            deleted_count = await loop.run_in_executor(
                None,
                lambda: index_manager.delete_repository_commits(arguments["repo_id"])
            )
            return f"âœ“ {deleted_count}ê°œ ì»¤ë°‹ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. (Repo ID: {arguments['repo_id']})"

        elif tool_name == "check_index_health":
            index_manager = IndexManager(
                search_client=search_client,
                index_client=index_client,
                index_name=os.getenv("AZURE_SEARCH_INDEX_NAME", "git-commits")
            )
            health = await loop.run_in_executor(
                None,
                lambda: index_manager.check_index_health()
            )

            status_emoji = "âœ…" if health["status"] == "healthy" else "âš ï¸" if health["status"] == "degraded" else "âŒ"

            # êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ê²°ê³¼ ìƒì„±
            result_parts = [
                f"{status_emoji} **ì¸ë±ìŠ¤ ìƒíƒœ: {health['status']}**",
                "",
                f"**ì¸ë±ìŠ¤ ì´ë¦„**: {health.get('index_name', 'N/A')}",
                f"**ì¸ë±ìŠ¤ ì¡´ì¬**: {'âœ“' if health.get('index_exists') else 'âœ—'}",
                f"**ì´ ë¬¸ì„œ ìˆ˜**: {health.get('total_documents', 0):,}",
                f"**ê²€ìƒ‰ ê¸°ëŠ¥**: {'ì •ìƒ' if health.get('search_works') else 'ì˜¤ë¥˜'}"
            ]

            if "message" in health:
                result_parts.append("")
                result_parts.append(f"**ë©”ì‹œì§€**: {health['message']}")

            return "\n".join(result_parts)

        elif tool_name == "search_commits_by_date":
            # ë‚ ì§œ ë²”ìœ„ë¡œ ì»¤ë°‹ ì¡°íšŒ
            repo_path = arguments.get("repo_path")
            since = arguments.get("since")
            until = arguments.get("until")
            top = arguments.get("top", 50)

            # í•„í„° êµ¬ì„±
            filters = []

            if repo_path:
                from src.indexer import normalize_repo_identifier
                repo_id = normalize_repo_identifier(repo_path)
                filters.append(f"repo_id eq '{repo_id}'")

            if since:
                filters.append(f"date ge {since}T00:00:00Z")

            if until:
                filters.append(f"date le {until}T23:59:59Z")

            filter_expr = " and ".join(filters) if filters else None

            try:
                results = search_client.search(
                    search_text="*",
                    filter=filter_expr,
                    select=["id", "message", "author", "date", "files_summary", "repository_path"],
                    order_by=["date desc"],
                    top=min(top, MAX_SEARCH_TOP)
                )

                commits = []
                for result in results:
                    commits.append({
                        "commit_id": result.get("id", ""),
                        "message": result.get("message", ""),
                        "author": result.get("author", ""),
                        "date": result.get("date", ""),
                        "files": result.get("files_summary", ""),
                        "repository": result.get("repository_path", "")
                    })

                if not commits:
                    return f"í•´ë‹¹ ê¸°ê°„ì— ì¸ë±ì‹±ëœ ì»¤ë°‹ì´ ì—†ìŠµë‹ˆë‹¤. (since: {since or 'ì œí•œì—†ìŒ'}, until: {until or 'ì œí•œì—†ìŒ'})"

                # ê²°ê³¼ ìš”ì•½ (í˜ì´ë¡œë“œ í¬ê¸° ì œí•œ)
                summary = f"ğŸ“… ë‚ ì§œ ë²”ìœ„ ê²€ìƒ‰ ê²°ê³¼: {len(commits)}ê°œ ì»¤ë°‹\n"
                summary += f"ê¸°ê°„: {since or 'ì‹œì‘'} ~ {until or 'í˜„ì¬'}\n\n"
                for i, c in enumerate(commits[:10], 1):  # ìµœëŒ€ 10ê°œë§Œ
                    summary += f"{i}. {c['message'][:80]}... (by {c['author']}, {c['date'][:10]})\n"
                if len(commits) > 10:
                    summary += f"\n...ì™¸ {len(commits)-10}ê°œ ì»¤ë°‹"
                return summary

            except Exception as e:
                logger.error(f"Failed to search commits by date: {e}")
                return f"ë‚ ì§œ ë²”ìœ„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

        else:
            return f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool_name}"

    except Exception as e:
        logger.error(f"Tool execution error: {e}")
        return f"ë„êµ¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"


@cl.set_starters
async def set_starters():
    """ì´ˆê¸° ì‹œì‘ í™”ë©´ì— í‘œì‹œí•  ìŠ¤íƒ€í„° ì œì•ˆ - Chainlit starters ê¸°ëŠ¥

    Icons8 MCPë¥¼ í†µí•´ ì „ë¬¸ì ì¸ ì•„ì´ì½˜ ì ìš©:
    - Database (1476): ì €ì¥ì†Œ ì¸ë±ì‹±
    - Commit Git (33279): ì»¤ë°‹ ìš”ì•½
    - Users/Group (102261): ê¸°ì—¬ì ë¶„ì„
    - Bug (417): ë²„ê·¸ ìˆ˜ì • ì»¤ë°‹
    """
    return [
        cl.Starter(
            label="ì €ì¥ì†Œ ì¸ë±ì‹± ì‹œì‘",
            message="í˜„ì¬ ì €ì¥ì†Œì˜ ì»¤ë°‹ íˆìŠ¤í† ë¦¬ë¥¼ ì¸ë±ì‹±í•´ì£¼ì„¸ìš”. ì €ì¥ì†Œ ê·œëª¨ë¥¼ ë¨¼ì € í™•ì¸í•˜ê³  ì ì ˆí•œ ê°œìˆ˜ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.",
            icon="/public/icons/icon_db_1476_64.png",
        ),
        cl.Starter(
            label="ìµœê·¼ ì»¤ë°‹ ìš”ì•½",
            message="ìµœê·¼ 10ê°œì˜ ì»¤ë°‹ì„ ìš”ì•½í•´ì£¼ì„¸ìš”. ì£¼ìš” ë³€ê²½ì‚¬í•­ê³¼ íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.",
            icon="/public/icons/icon_commit_33279_64.png",
        ),
        cl.Starter(
            label="ê¸°ì—¬ì í™œë™ ë¶„ì„",
            message="ì €ì¥ì†Œì˜ ê¸°ì—¬ìë³„ í™œë™ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. ëˆ„ê°€ ê°€ì¥ ë§ì´ ê¸°ì—¬í–ˆëŠ”ì§€, ì£¼ìš” ë‹´ë‹¹ ì˜ì—­ì€ ë¬´ì—‡ì¸ì§€ ì•Œë ¤ì£¼ì„¸ìš”.",
            icon="/public/icons/icon_users_102261_64.png",
        ),
        cl.Starter(
            label="ë²„ê·¸ ìˆ˜ì • ì»¤ë°‹ ì°¾ê¸°",
            message="ë²„ê·¸ ìˆ˜ì •ê³¼ ê´€ë ¨ëœ ì»¤ë°‹ë“¤ì„ ì°¾ì•„ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”. ì–´ë–¤ ë²„ê·¸ë“¤ì´ ì£¼ë¡œ ìˆ˜ì •ë˜ì—ˆëŠ”ì§€ ìš”ì•½í•´ì£¼ì„¸ìš”.",
            icon="/public/icons/icon_bug_417_64.png",
        ),
    ]


@cl.on_chat_start
async def on_chat_start():
    """ì±„íŒ… ì‹œì‘ ì‹œ ì´ˆê¸°í™” - Chainlit chat life cycleì˜ on_chat_start í›…

    Note: í™˜ì˜ ë©”ì‹œì§€ëŠ” chainlit.mdì—ì„œ ì²˜ë¦¬ë¨
    ì´ í•¨ìˆ˜ëŠ” ì„¸ì…˜ ì´ˆê¸°í™”ë§Œ ìˆ˜í–‰í•˜ì—¬ startersê°€ ë¨¼ì € ë³´ì´ë„ë¡ í•¨
    """
    try:
        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        openai_client, search_client, index_client = initialize_clients()

        # ì„¸ì…˜ ë³€ìˆ˜ ì„¤ì •
        cl.user_session.set("openai_client", openai_client)
        cl.user_session.set("search_client", search_client)
        cl.user_session.set("index_client", index_client)
        cl.user_session.set("conversation_history", [
            {"role": "system", "content": get_system_prompt()}
        ])
        cl.user_session.set("is_processing", False)

        logger.info("Chat session started - clients initialized")

    except Exception as e:
        logger.error(f"Failed to start chat: {e}")
        # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œì—ë§Œ ë©”ì‹œì§€ í‘œì‹œ
        await cl.Message(content=f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}\n\ní˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.").send()


@cl.on_message
async def on_message(message: cl.Message):
    """ë©”ì‹œì§€ ì²˜ë¦¬ - Chainlit chat life cycleì˜ on_message í›…"""
    try:
        # ì²˜ë¦¬ ì¤‘ì¸ ë©”ì‹œì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
        is_processing = cl.user_session.get("is_processing")
        if is_processing:
            await cl.Message(content="ì´ì „ ìš”ì²­ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.").send()
            return

        # ì²˜ë¦¬ ì‹œì‘ í”Œë˜ê·¸ ì„¤ì •
        cl.user_session.set("is_processing", True)

        openai_client = cl.user_session.get("openai_client")
        search_client = cl.user_session.get("search_client")
        index_client = cl.user_session.get("index_client")
        conversation_history = cl.user_session.get("conversation_history")

        if not openai_client or not search_client or not index_client:
            cl.user_session.set("is_processing", False)
            await cl.Message(content="ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.").send()
            return

        user_message = message.content
        conversation_history.append({"role": "user", "content": user_message})

        # ëŒ€í™” ê¸°ë¡ ê¸¸ì´ ì œí•œ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ìµœê·¼ Nê°œ ë©”ì‹œì§€)
        max_history_length = MAX_CONVERSATION_MESSAGES + 1  # +1 for system prompt
        if len(conversation_history) > max_history_length:
            system_msg = conversation_history[0]
            recent_messages = conversation_history[-(MAX_CONVERSATION_MESSAGES):]
            conversation_history = [system_msg] + recent_messages
            logger.info(f"Conversation history trimmed to {len(conversation_history)} messages")

        # ë¶„ì„ ì¤‘ ë©”ì‹œì§€ë¥¼ ë¨¼ì € í‘œì‹œ (Stepë“¤ì´ ì´ ì•„ë˜ì—ì„œ ì‹¤í–‰ë¨)
        msg = cl.Message(content="â³ ìš”ì²­ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        await msg.send()

        max_iterations = 10
        iteration = 0
        has_tool_result = False  # ë„êµ¬ ì‹¤í–‰ í›„ ìµœì¢… ì‘ë‹µ ë³´ì¥ìš© í”Œë˜ê·¸

        while iteration < max_iterations:
            iteration += 1

            # ğŸ”§ ì „ì²´ ë‹¨ê³„ë¥¼ ê°ì‹¸ëŠ” ë¶€ëª¨ Step
            async with cl.Step(name=f"ğŸ”§ ì‘ì—… ìˆ˜í–‰ (ë‹¨ê³„ {iteration})", type="run", show_input=False) as parent_step:
                try:
                    # ğŸ’­ ë¶„ì„ ë‹¨ê³„ (ìì‹ Step)
                    async with cl.Step(name="ğŸ’­ ë¶„ì„ ì¤‘...", parent_id=parent_step.id, type="llm", show_input=False) as analysis_step:
                        response = openai_client.chat.completions.create(
                            model=os.getenv("AZURE_OPENAI_MODEL", "gpt-4o-mini"),
                            messages=conversation_history,
                            tools=AVAILABLE_TOOLS,
                            tool_choice="auto",
                            temperature=0.7,
                            max_tokens=1000,
                            stream=False  # ë„êµ¬ ì„ íƒì„ ìœ„í•´ non-streaming
                        )

                        assistant_message = response.choices[0].message

                        # LLMì˜ ìƒê° í‘œì‹œ (ê°„ê²°í•˜ê²Œ)
                        if assistant_message.tool_calls:
                            tool_names = [tc.function.name for tc in assistant_message.tool_calls]
                            analysis_step.output = f"ğŸ”§ ë„êµ¬ ì„ íƒ: {', '.join(tool_names)}"
                        elif assistant_message.content:
                            analysis_step.output = "âœ… ì‘ë‹µ ì¤€ë¹„ ì™„ë£Œ"

                    # ë„êµ¬ í˜¸ì¶œ ì—†ì´ ìµœì¢… ì‘ë‹µë§Œ ìˆëŠ” ê²½ìš° - ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹¤ì‹œ ìƒì„±
                    if not assistant_message.tool_calls:
                        # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
                        msg.content = ""

                        streaming_response = openai_client.chat.completions.create(
                            model=os.getenv("AZURE_OPENAI_MODEL", "gpt-4o-mini"),
                            messages=conversation_history,
                            temperature=0.7,
                            max_tokens=1000,
                            stream=True
                        )

                        final_content = ""
                        for chunk in streaming_response:
                            # ì•ˆì „í•˜ê²Œ choicesì™€ delta ì²´í¬
                            if chunk.choices and len(chunk.choices) > 0:
                                delta = chunk.choices[0].delta
                                if delta and hasattr(delta, 'content') and delta.content:
                                    token = delta.content
                                    final_content += token
                                    await msg.stream_token(token)

                        await msg.update()

                        if final_content:
                            conversation_history.append({
                                "role": "assistant",
                                "content": final_content
                            })
                        parent_step.output = "âœ… ì‘ë‹µ ì™„ë£Œ"
                        break

                    conversation_history.append({
                        "role": "assistant",
                        "content": assistant_message.content,
                        "tool_calls": [
                            {
                                "id": tc.id,
                                "type": "function",
                                "function": {
                                    "name": tc.function.name,
                                    "arguments": tc.function.arguments
                                }
                            }
                            for tc in assistant_message.tool_calls
                        ]
                    })

                    for tool_call in assistant_message.tool_calls:
                        tool_name = tool_call.function.name
                        tool_args = json.loads(tool_call.function.arguments)

                        # ğŸ› ï¸ ë„êµ¬ ì‹¤í–‰ ë‹¨ê³„ (ìì‹ Step)
                        async with cl.Step(name=f"ğŸ› ï¸ {tool_name}", parent_id=parent_step.id, type="tool", show_input=False) as tool_step:
                            # Step ë°–ì—ì„œ ë„êµ¬ ì‹¤í–‰ (AskActionMessageê°€ ìˆ¨ì§€ ì•Šë„ë¡)
                            tool_result = await execute_tool(
                                tool_name=tool_name,
                                arguments=tool_args,
                                openai_client=openai_client,
                                search_client=search_client,
                                index_client=index_client
                            )

                            # ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ í”Œë˜ê·¸ ì„¤ì •
                            has_tool_result = True

                            # ê²°ê³¼ í¬ê¸° ì œí•œ (SocketIO í˜ì´ë¡œë“œ ì œí•œ íšŒí”¼)
                            display_result = tool_result[:MAX_TOOL_RESULT_DISPLAY] if len(tool_result) > MAX_TOOL_RESULT_DISPLAY else tool_result

                            # Step ì¶œë ¥ì€ ê°„ê²°í•˜ê²Œ
                            if len(tool_result) > MAX_TOOL_RESULT_DISPLAY:
                                tool_step.output = f"âœ… ì™„ë£Œ (ê²°ê³¼ {len(tool_result):,}ì, ì¼ë¶€ ìƒëµ)"
                            else:
                                tool_step.output = f"âœ… ì™„ë£Œ"

                            # LLMì—ê²Œ ì „ë‹¬í•  ê²°ê³¼ëŠ” ë” ê¸¸ê²Œ í—ˆìš©í•˜ë˜ ì œí•œ
                            truncated_result = tool_result[:MAX_TOOL_RESULT_TO_LLM]
                            if len(tool_result) > MAX_TOOL_RESULT_TO_LLM:
                                truncated_result += f"\n\n...(ì´ {len(tool_result)}ì ì¤‘ {MAX_TOOL_RESULT_TO_LLM}ì í‘œì‹œ)"
                                logger.warning(f"Tool result truncated: {len(tool_result)} -> {MAX_TOOL_RESULT_TO_LLM}")

                            conversation_history.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "content": truncated_result
                            })

                    parent_step.output = "âœ… ë„êµ¬ ì‹¤í–‰ ì™„ë£Œ"

                    # ğŸ”„ ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ìŒ í–‰ë™ ê²°ì • (tool_calls í™•ì¸ì„ ìœ„í•´ non-streaming)
                    logger.info("Checking next action after tool execution...")
                    next_response = openai_client.chat.completions.create(
                        model=os.getenv("AZURE_OPENAI_MODEL", "gpt-4o-mini"),
                        messages=conversation_history,
                        tools=AVAILABLE_TOOLS,
                        tool_choice="auto",
                        temperature=0.7,
                        max_tokens=1000,
                        stream=False
                    )

                    next_message = next_response.choices[0].message

                    # ì¶”ê°€ ë„êµ¬ í˜¸ì¶œì´ ìˆìœ¼ë©´ í˜„ì¬ iterationì—ì„œ ê³„ì† ì‹¤í–‰
                    if next_message.tool_calls:
                        logger.info(f"More tool calls needed: {[tc.function.name for tc in next_message.tool_calls]}")

                        # assistant ë©”ì‹œì§€ ì¶”ê°€
                        conversation_history.append({
                            "role": "assistant",
                            "content": next_message.content,
                            "tool_calls": [
                                {
                                    "id": tc.id,
                                    "type": "function",
                                    "function": {
                                        "name": tc.function.name,
                                        "arguments": tc.function.arguments
                                    }
                                }
                                for tc in next_message.tool_calls
                            ]
                        })

                        # ì¶”ê°€ ë„êµ¬ë“¤ì„ í˜„ì¬ iterationì—ì„œ ì‹¤í–‰
                        for tool_call in next_message.tool_calls:
                            tool_name = tool_call.function.name
                            tool_args = json.loads(tool_call.function.arguments)

                            async with cl.Step(name=f"ğŸ› ï¸ {tool_name} (ì¶”ê°€)", parent_id=parent_step.id, type="tool", show_input=False) as extra_tool_step:
                                extra_tool_result = await execute_tool(
                                    tool_name=tool_name,
                                    arguments=tool_args,
                                    openai_client=openai_client,
                                    search_client=search_client,
                                    index_client=index_client
                                )

                                truncated_extra_result = extra_tool_result[:MAX_TOOL_RESULT_TO_LLM]
                                if len(extra_tool_result) > MAX_TOOL_RESULT_TO_LLM:
                                    truncated_extra_result += f"\n\n...(ì´ {len(extra_tool_result)}ì ì¤‘ {MAX_TOOL_RESULT_TO_LLM}ì í‘œì‹œ)"

                                conversation_history.append({
                                    "role": "tool",
                                    "tool_call_id": tool_call.id,
                                    "content": truncated_extra_result
                                })

                                extra_tool_step.output = "âœ… ì™„ë£Œ"

                        parent_step.output = "ğŸ”„ ì¶”ê°€ ë„êµ¬ ì‹¤í–‰ í•„ìš”"
                        # ë‹¤ìŒ iterationìœ¼ë¡œ ê³„ì†
                        continue

                    # í…ìŠ¤íŠ¸ ì‘ë‹µë§Œ ìˆìœ¼ë©´ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í‘œì‹œ
                    if next_message.content:
                        logger.info("Final response after tool execution, streaming to user...")
                        async with cl.Step(name="ğŸ’¬ ì‘ë‹µ ìƒì„±", parent_id=parent_step.id, type="llm", show_input=False) as response_step:
                            msg.content = ""

                            # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹¤ì‹œ ìƒì„±
                            streaming_response = openai_client.chat.completions.create(
                                model=os.getenv("AZURE_OPENAI_MODEL", "gpt-4o-mini"),
                                messages=conversation_history,
                                temperature=0.7,
                                max_tokens=1000,
                                stream=True
                            )

                            response_content = ""
                            for chunk in streaming_response:
                                if chunk.choices and len(chunk.choices) > 0:
                                    delta = chunk.choices[0].delta
                                    if delta and hasattr(delta, 'content') and delta.content:
                                        token = delta.content
                                        response_content += token
                                        await msg.stream_token(token)

                            await msg.update()

                            if response_content:
                                conversation_history.append({
                                    "role": "assistant",
                                    "content": response_content
                                })
                            response_step.output = "âœ… ì‘ë‹µ ì™„ë£Œ"
                            has_tool_result = True
                            break  # ìµœì¢… ì‘ë‹µ í›„ ì¢…ë£Œ

                except Exception as e:
                    logger.error(f"Error in iteration {iteration}: {e}")
                    parent_step.output = f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                    break

        # ë„êµ¬ ì‹¤í–‰ í›„ ìµœì¢… ì‘ë‹µì´ ì—†ìœ¼ë©´ fallback (ì¼ë°˜ì ìœ¼ë¡œ ìœ„ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ê±°ì˜ ì‹¤í–‰ ì•ˆë¨)
        if has_tool_result and iteration < max_iterations and not msg.content:
            try:
                logger.warning("Fallback: Forcing final response after tool execution")
                # âœ… ìµœì¢… ì‘ë‹µì€ ìµœìƒìœ„ ë ˆë²¨ë¡œ (parent ì—†ìŒ)
                async with cl.Step(name="âœ… ìµœì¢… ì‘ë‹µ (Fallback)", type="llm", show_input=False) as final_step:
                    # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ ìƒì„± (ê¹œë¹¡ì´ëŠ” ì»¤ì„œ í‘œì‹œ)
                    msg.content = ""  # ë©”ì‹œì§€ ì´ˆê¸°í™”

                    final_response = openai_client.chat.completions.create(
                        model=os.getenv("AZURE_OPENAI_MODEL", "gpt-4o-mini"),
                        messages=conversation_history,
                        temperature=0.7,
                        max_tokens=1000,
                        stream=True  # ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
                    )

                    final_content = ""
                    for chunk in final_response:
                        # ì•ˆì „í•˜ê²Œ choicesì™€ delta ì²´í¬
                        if chunk.choices and len(chunk.choices) > 0:
                            delta = chunk.choices[0].delta
                            if delta and hasattr(delta, 'content') and delta.content:
                                token = delta.content
                                final_content += token
                                await msg.stream_token(token)

                    await msg.update()

                    if final_content:
                        conversation_history.append({
                            "role": "assistant",
                            "content": final_content
                        })
                    final_step.output = "âœ… ì‘ë‹µ ì™„ë£Œ"
            except Exception as e:
                logger.error(f"Error generating final response: {e}", exc_info=True)
                msg.content = "ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
                await msg.update()

        if iteration >= max_iterations and not msg.content:
            msg.content = "âš ï¸ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ìš”ì²­ì„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            await msg.update()

        cl.user_session.set("conversation_history", conversation_history)

    except Exception as e:
        logger.error(f"Message handling error: {e}")
        await cl.Message(content=f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}").send()
    finally:
        # ì²˜ë¦¬ ì™„ë£Œ í”Œë˜ê·¸ í•´ì œ
        cl.user_session.set("is_processing", False)


@cl.on_stop
async def on_stop():
    """ì‚¬ìš©ìê°€ ì¤‘ì§€ ë²„íŠ¼ì„ í´ë¦­í–ˆì„ ë•Œ - Chainlit chat life cycleì˜ on_stop í›…"""
    logger.info("User requested to stop the task")
    cl.user_session.set("is_processing", False)
    await cl.Message(content="â¸ï¸ ì‘ì—…ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.").send()


@cl.on_chat_end
async def on_chat_end():
    """ì±„íŒ… ì„¸ì…˜ ì¢…ë£Œ ì‹œ - Chainlit chat life cycleì˜ on_chat_end í›…"""
    logger.info("Chat session ended")
    # ì„¸ì…˜ ì •ë¦¬ (í•„ìš”ì‹œ)
    cl.user_session.set("is_processing", False)
    cl.user_session.set("conversation_history", None)
    cl.user_session.set("openai_client", None)
    cl.user_session.set("search_client", None)
    cl.user_session.set("index_client", None)


# í…ŒìŠ¤íŠ¸ í˜¸í™˜ì„ ìœ„í•œ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸ ì‹¬ë³¼ ì œê³µ

def start() -> None:
    """Chainlit ì•± ì‹œì‘ìš© ì—”íŠ¸ë¦¬í¬ì¸íŠ¸(í…ŒìŠ¤íŠ¸ì—ì„œ ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸)."""
    logger.info("start() called - Chainlit entry placeholder")


def main() -> None:
    """ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸(í…ŒìŠ¤íŠ¸ì—ì„œ ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸)."""
    logger.info("main() called - entry placeholder")


if __name__ == "__main__":
    import sys
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

