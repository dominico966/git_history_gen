"""
ë„êµ¬ í•¨ìˆ˜ë“¤ - Streamlit ì•±ì—ì„œ ì‚¬ìš©í•  ë‹¤ì–‘í•œ ê¸°ëŠ¥ ì œê³µ
"""

import os
from src.document_generator import DocumentGenerator
from typing import List, Dict, Optional, Any
from openai import AzureOpenAI
from azure.search.documents import SearchClient
from azure.search.documents.models import VectorizedQuery
from src.embedding import embed_texts
from collections import defaultdict
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def normalize_repo_identifier(repo_path: str) -> str:
    """
    ì €ì¥ì†Œ ê²½ë¡œ ë˜ëŠ” URLì„ ì •ê·œí™”ëœ ì‹ë³„ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    (indexer.pyì˜ í•¨ìˆ˜ì™€ ë™ì¼í•œ ë¡œì§)
    """
    import hashlib
    from urllib.parse import urlparse
    from pathlib import Path

    # git@ í˜•ì‹ì˜ SSH URL ì²˜ë¦¬ (ì˜ˆ: git@github.com:user/repo.git)
    if repo_path.startswith('git@'):
        # git@github.com:user/repo.git -> github.com/user/repo í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        parts = repo_path.replace('git@', '').replace(':', '/')
        normalized = parts.rstrip('/').removesuffix('.git').lower()
    # ì¼ë°˜ URLì¸ ê²½ìš° (http://, https://, git://, ssh://)
    elif repo_path.startswith(('http://', 'https://', 'git://', 'ssh://')):
        parsed = urlparse(repo_path)
        path = parsed.path.rstrip('/').removesuffix('.git')
        normalized = f"{parsed.scheme}://{parsed.netloc}{path}".lower()
    else:
        # ë¡œì»¬ ê²½ë¡œì¸ ê²½ìš°
        try:
            abs_path = Path(repo_path).resolve()
            normalized = str(abs_path).lower()
        except Exception as e:
            # ê²½ë¡œ ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
            logger.warning(f"Failed to resolve path '{repo_path}': {e}, using original")
            normalized = repo_path.lower()

    # SHA-256 í•´ì‹œë¡œ ë³€í™˜
    hash_obj = hashlib.sha256(normalized.encode('utf-8'))
    repo_id = hash_obj.hexdigest()[:16]

    return repo_id


def get_commit_count(
    repo_path: str,
    since: Optional[str] = None,
    until: Optional[str] = None
) -> Dict[str, Any]:
    """
    ì €ì¥ì†Œì˜ ì´ ì»¤ë°‹ ê°œìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    ìºì‹œëœ ì €ì¥ì†Œì—ì„œ ì •í™•í•œ ê°œìˆ˜ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

    Args:
        repo_path: Git ì €ì¥ì†Œ ê²½ë¡œ ë˜ëŠ” URL
        since: ì‹œì‘ ë‚ ì§œ (ISO 8601 í˜•ì‹, ì˜ˆ: '2024-01-01')
        until: ì¢…ë£Œ ë‚ ì§œ (ISO 8601 í˜•ì‹, ì˜ˆ: '2024-12-31')

    Returns:
        Dict: ì»¤ë°‹ ê°œìˆ˜ ì •ë³´
    """
    try:
        logger.info(f"Counting commits for {repo_path} (since={since}, until={until})")

        # ì›ê²© ì €ì¥ì†Œì¸ ê²½ìš°
        if repo_path.startswith(('http://', 'https://', 'git@')):
            # ìºì‹œëœ í´ë¡  ì‚¬ìš© (ì •í™•í•œ ê°œìˆ˜)
            logger.info("Using cached repository for accurate commit count...")
            from src.repo_cache import RepoCloneCache

            cache = RepoCloneCache()

            # ë‚ ì§œ í•„í„°ê°€ ìˆìœ¼ë©´ ì¶©ë¶„í•œ depth í•„ìš”
            if since or until:
                # ë‚ ì§œ í•„í„°ê°€ ìˆìœ¼ë©´ ë” ê¹Šê²Œ fetch
                cached_path = cache.get_or_clone(repo_path, depth=1000)
            else:
                # ë‚ ì§œ í•„í„° ì—†ìœ¼ë©´ shallow cloneìœ¼ë¡œ ì¶©ë¶„
                cached_path = cache.get_or_clone(repo_path)

            # ìºì‹œëœ ì €ì¥ì†Œì—ì„œ ì»¤ë°‹ ê°œìˆ˜ ì¡°íšŒ
            import git
            repo = git.Repo(cached_path)

            args = ['--count', 'HEAD']
            if since:
                args.append(f'--since={since}')
            if until:
                args.append(f'--until={until}')

            count = int(repo.git.rev_list(*args))
            repo.close()

            period_text = ""
            if since and until:
                period_text = f" ({since} ~ {until})"
            elif since:
                period_text = f" ({since} ì´í›„)"
            elif until:
                period_text = f" ({until} ì´ì „)"

            logger.info(f"âœ“ Cached repo: {count:,} commits{period_text}")

            # 0ê°œ ì»¤ë°‹ì¸ ê²½ìš° ëª…í™•í•œ ë©”ì‹œì§€ ìƒì„±
            if count == 0:
                if since or until:
                    message = f"âš ï¸ ì§€ì •í•œ ê¸°ê°„{period_text}ì—ëŠ” ì»¤ë°‹ì´ ì—†ìŠµë‹ˆë‹¤. ë‚ ì§œ ë²”ìœ„ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”."
                else:
                    message = "âš ï¸ ì´ ì €ì¥ì†Œì—ëŠ” ì»¤ë°‹ì´ ì—†ìŠµë‹ˆë‹¤."

                return {
                    "repo_path": repo_path,
                    "commit_count": 0,
                    "has_commits": False,
                    "since": since,
                    "until": until,
                    "method": "cached_clone",
                    "message": message
                }

            return {
                "repo_path": repo_path,
                "commit_count": count,
                "has_commits": True,
                "since": since,
                "until": until,
                "method": "cached_clone",
                "message": f"ì´ {count:,}ê°œ ì»¤ë°‹{period_text}"
            }

        # ë¡œì»¬ ì €ì¥ì†Œì¸ ê²½ìš° - ê¸°ì¡´ ë°©ì‹ ìœ ì§€
        generator = DocumentGenerator(repo_path)
        try:
            repo = generator.repo
            args = ['--count', 'HEAD']

            if since:
                args.append(f'--since={since}')
            if until:
                args.append(f'--until={until}')

            commit_count = int(repo.git.rev_list(*args))

            period_text = ""
            if since and until:
                period_text = f" ({since} ~ {until})"
            elif since:
                period_text = f" ({since} ì´í›„)"
            elif until:
                period_text = f" ({until} ì´ì „)"

            # 0ê°œ ì»¤ë°‹ì¸ ê²½ìš° ëª…í™•í•œ ë©”ì‹œì§€ ìƒì„±
            if commit_count == 0:
                if since or until:
                    message = f"âš ï¸ ì§€ì •í•œ ê¸°ê°„{period_text}ì—ëŠ” ì»¤ë°‹ì´ ì—†ìŠµë‹ˆë‹¤. ë‚ ì§œ ë²”ìœ„ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”."
                else:
                    message = "âš ï¸ ì´ ì €ì¥ì†Œì—ëŠ” ì»¤ë°‹ì´ ì—†ìŠµë‹ˆë‹¤."

                return {
                    "repo_path": repo_path,
                    "commit_count": 0,
                    "has_commits": False,
                    "since": since,
                    "until": until,
                    "method": "local",
                    "message": message
                }

            return {
                "repo_path": repo_path,
                "commit_count": commit_count,
                "has_commits": True,
                "since": since,
                "until": until,
                "method": "local",
                "message": f"ì´ {commit_count:,}ê°œ ì»¤ë°‹{period_text}"
            }
        finally:
            generator.close()

    except Exception as e:
        logger.error(f"Error counting commits: {e}")
        return {
            "repo_path": repo_path,
            "commit_count": 0,
            "has_commits": False,
            "error": str(e),
            "message": f"ì»¤ë°‹ ê°œìˆ˜ í™•ì¸ ì‹¤íŒ¨: {str(e)}"
        }



def get_commit_summary(
    repo_path: str,
    llm_client: AzureOpenAI,
    limit: int = 50
) -> str:
    """
    Git ì €ì¥ì†Œì˜ ìµœê·¼ ì»¤ë°‹ë“¤ì„ ìš”ì•½í•©ë‹ˆë‹¤.

    Args:
        repo_path: Git ì €ì¥ì†Œ ê²½ë¡œ
        llm_client: Azure OpenAI í´ë¼ì´ì–¸íŠ¸
        limit: ë¶„ì„í•  ì»¤ë°‹ ìˆ˜

    Returns:
        str: LLMì´ ìƒì„±í•œ ì»¤ë°‹ ìš”ì•½
    """
    try:
        logger.info(f"Generating summary for {repo_path} (last {limit} commits)")

        generator = DocumentGenerator(repo_path)
        try:
            commits = generator.get_commits(limit=limit)
        finally:
            generator.close()  # íŒŒì¼ í•¸ë“¤ í•´ì œ

        if not commits:
            return "No commits found in the repository."

        # ì»¤ë°‹ ì •ë³´ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì •ë¦¬
        commit_summary = []
        for commit in commits[:10]:  # ìµœê·¼ 10ê°œë§Œ ìƒì„¸ í‘œì‹œ
            files_changed = len(commit['files'])
            lines_added = sum(f.get('lines_added', 0) for f in commit['files'])
            lines_deleted = sum(f.get('lines_deleted', 0) for f in commit['files'])

            commit_summary.append(
                f"- [{commit['date'][:10]}] {commit['author']}: {commit['message'][:100]}\n"
                f"  Files: {files_changed}, +{lines_added}/-{lines_deleted}"
            )

        # í†µê³„ ì •ë³´
        total_authors = len(set(c['author'] for c in commits))
        total_files = sum(len(c['files']) for c in commits)

        # LLMì—ê²Œ ìš”ì•½ ìš”ì²­
        prompt = f"""ë‹¤ìŒì€ Git ì €ì¥ì†Œì˜ ìµœê·¼ {len(commits)}ê°œ ì»¤ë°‹ ì •ë³´ì…ë‹ˆë‹¤.

ìµœê·¼ 10ê°œ ì»¤ë°‹ ìƒì„¸:
{chr(10).join(commit_summary)}

ì „ì²´ í†µê³„:
- ì´ ì»¤ë°‹ ìˆ˜: {len(commits)}
- ê¸°ì—¬ì ìˆ˜: {total_authors}
- ë³€ê²½ëœ íŒŒì¼ ìˆ˜: {total_files}

ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•˜ì—¬ ìš”ì•½í•´ì£¼ì„¸ìš”:
1. ìµœê·¼ ë³€ê²½ì‚¬í•­ì˜ ì£¼ìš” íŠ¹ì§•
2. ê°€ì¥ í™œë°œí•˜ê²Œ ë³€ê²½ëœ ì˜ì—­
3. ì£¼ìš” ê¸°ì—¬ì í™œë™
4. ì£¼ëª©í•  ë§Œí•œ íŒ¨í„´ì´ë‚˜ íŠ¸ë Œë“œ

ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        from openai.types.chat import ChatCompletionMessageParam

        messages: list[ChatCompletionMessageParam] = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ Git ì»¤ë°‹ íˆìŠ¤í† ë¦¬ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]

        response = llm_client.chat.completions.create(
            model=os.getenv("AZURE_OPENAI_MODEL", "gpt-4.1-mini"),
            messages=messages,
            temperature=0.7,
            max_tokens=1000
        )

        return response.choices[0].message.content

    except Exception as e:
        logger.error(f"Error generating commit summary: {e}")
        return f"Error generating summary: {str(e)}"


def search_commits(
    query: str,
    search_client: SearchClient,
    openai_client: AzureOpenAI,
    top: int = 10,
    repo_path: Optional[str] = None
) -> List[Dict]:
    """
    ìì—°ì–´ ì¿¼ë¦¬ë¡œ ì»¤ë°‹ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤ (ë²¡í„° + í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰).

    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        search_client: Azure AI Search í´ë¼ì´ì–¸íŠ¸
        openai_client: Azure OpenAI í´ë¼ì´ì–¸íŠ¸
        top: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
        repo_path: íŠ¹ì • ì €ì¥ì†Œë§Œ ê²€ìƒ‰ (ì„ íƒì )

    Returns:
        List[Dict]: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    try:
        # ğŸ” ê²€ìƒ‰ ì¡°ê±´ ìš”ì•½ ë¡œê·¸
        logger.info("=" * 80)
        logger.info("ğŸ” SEARCH REQUEST SUMMARY")
        logger.info(f"  ğŸ“ Query: '{query}'")
        logger.info(f"  ğŸ“Š Top Results: {top}")
        logger.info(f"  ğŸ“ Repository Filter: {repo_path if repo_path else 'ALL repositories'}")
        if repo_path:
            repo_id = normalize_repo_identifier(repo_path)
            logger.info(f"  ğŸ”‘ Repo ID: {repo_id}")
        logger.info("=" * 80)

        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embeddings = embed_texts([query], openai_client)

        if not query_embeddings or not query_embeddings[0]:
            logger.error("Failed to generate query embedding")
            return []

        # ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        vector_query = VectorizedQuery(
            vector=query_embeddings[0],
            k_nearest_neighbors=top,
            fields="content_vector"
        )

        # ì €ì¥ì†Œ í•„í„° ì¶”ê°€ (repo_pathê°€ ì œê³µëœ ê²½ìš°)
        filter_expr = None
        if repo_path:
            repo_id = normalize_repo_identifier(repo_path)
            filter_expr = f"repo_id eq '{repo_id}'"
            logger.info(f"ğŸ“Œ Applying filter: {filter_expr}")

        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í…ìŠ¤íŠ¸ + ë²¡í„°)
        logger.info(f"ğŸ” Executing hybrid search (text + vector)...")
        results = search_client.search(
            search_text=query,
            vector_queries=[vector_query],
            filter=filter_expr,
            select=[
                "id", "message", "author", "date", "files_summary",
                "lines_added", "lines_deleted",
                "repo_id", "repository_path",
                "change_context_summary", "impact_scope",
                "modified_functions", "modified_classes",
                "code_complexity", "relationship_type"
            ],
            top=top
        )

        search_results = []
        for result in results:
            search_results.append({
                "commit_id": result.get("id", ""),
                "message": result.get("message", ""),
                "author": result.get("author", ""),
                "date": result.get("date", ""),
                "files": result.get("files_summary", ""),
                "changes": f"+{result.get('lines_added', 0)}/-{result.get('lines_deleted', 0)}",
                "score": result.get("@search.score", 0),
                "repo_id": result.get("repo_id", ""),
                "repository": result.get("repository_path", ""),
                # ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„°
                "context": result.get("change_context_summary", ""),
                "impact": result.get("impact_scope", ""),
                "functions": result.get("modified_functions", ""),
                "classes": result.get("modified_classes", ""),
                "complexity": result.get("code_complexity", "unknown"),
                "relation": result.get("relationship_type", "sequential")
            })

        logger.info("=" * 80)
        logger.info(f"âœ… SEARCH COMPLETED: Found {len(search_results)} results")
        if search_results:
            logger.info(f"  ğŸ“Œ Top result: [{search_results[0]['commit_id'][:8]}] {search_results[0]['message'][:60]}...")
            logger.info(f"  ğŸ¯ Score range: {search_results[0]['score']:.4f} ~ {search_results[-1]['score']:.4f}")
        logger.info("=" * 80)
        return search_results

    except Exception as e:
        logger.error(f"Error searching commits: {e}")
        return []


def analyze_contributors(
    repo_path: str,
    criteria: Optional[str] = None,
    limit: Optional[int] = None,
    since: Optional[str] = None,
    until: Optional[str] = None
) -> Dict:
    """
    ê¸°ì—¬ìë³„ í™œë™ì„ ë¶„ì„í•©ë‹ˆë‹¤.

    Args:
        repo_path: Git ì €ì¥ì†Œ ê²½ë¡œ
        criteria: í‰ê°€ ê¸°ì¤€ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        limit: ë¶„ì„í•  ì»¤ë°‹ ìˆ˜
        since: ì‹œì‘ ë‚ ì§œ (ISO 8601 í˜•ì‹, ì˜ˆ: '2024-01-01')
        until: ì¢…ë£Œ ë‚ ì§œ (ISO 8601 í˜•ì‹, ì˜ˆ: '2024-12-31')

    Returns:
        Dict: ê¸°ì—¬ìë³„ í†µê³„
    """
    try:
        logger.info(f"Analyzing contributors for {repo_path} (since: {since}, until: {until})")

        generator = DocumentGenerator(repo_path)
        try:
            commits = generator.get_commits(
                limit=limit if limit else 1000,
                since=since,
                until=until
            )
        finally:
            generator.close()  # íŒŒì¼ í•¸ë“¤ í•´ì œ

        if not commits:
            return {"error": "No commits found"}

        # ê¸°ì—¬ìë³„ í†µê³„ ìˆ˜ì§‘
        contributor_stats = defaultdict(lambda: {
            "commit_count": 0,
            "files_changed": 0,
            "lines_added": 0,
            "lines_deleted": 0,
            "recent_commits": []
        })

        for commit in commits:
            author = commit['author']
            stats = contributor_stats[author]

            stats["commit_count"] += 1
            stats["files_changed"] += len(commit['files'])
            stats["lines_added"] += sum(f.get('lines_added', 0) for f in commit['files'])
            stats["lines_deleted"] += sum(f.get('lines_deleted', 0) for f in commit['files'])

            if len(stats["recent_commits"]) < 5:
                stats["recent_commits"].append({
                    "date": commit['date'][:10],
                    "message": commit['message'][:100]
                })

        # ê¸°ë³¸ í‰ê°€ ê¸°ì¤€ ì ìš© (ì—†ìœ¼ë©´)
        if not criteria:
            criteria = "ì»¤ë°‹ ìˆ˜, ë³€ê²½ ë¼ì¸ ìˆ˜"

        # ê²°ê³¼ë¥¼ ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        result = {
            "total_contributors": len(contributor_stats),
            "total_commits": len(commits),
            "evaluation_criteria": criteria,
            "contributors": []
        }

        # ì»¤ë°‹ ìˆ˜ë¡œ ì •ë ¬
        for author, stats in sorted(
            contributor_stats.items(),
            key=lambda x: x[1]["commit_count"],
            reverse=True
        ):
            total_lines = stats["lines_added"] + stats["lines_deleted"]
            result["contributors"].append({
                "name": author,
                "commits": stats["commit_count"],
                "files_changed": stats["files_changed"],
                "lines_added": stats["lines_added"],
                "lines_deleted": stats["lines_deleted"],
                "total_lines_changed": total_lines,
                "recent_commits": stats["recent_commits"]
            })

        logger.info(f"âœ“ Analyzed {len(result['contributors'])} contributors")
        return result

    except Exception as e:
        logger.error(f"Error analyzing contributors: {e}")
        return {"error": str(e)}


def find_frequent_bug_commits(
    repo_path: str,
    llm_client: AzureOpenAI,
    limit: int = 200
) -> List[Dict]:
    """
    ë²„ê·¸ ìˆ˜ì • ì»¤ë°‹ì„ ì°¾ìŠµë‹ˆë‹¤ (ì»¤ë°‹ ë©”ì‹œì§€ ê¸°ë°˜).

    Args:
        repo_path: Git ì €ì¥ì†Œ ê²½ë¡œ
        llm_client: Azure OpenAI í´ë¼ì´ì–¸íŠ¸ (ì¶”ê°€ ë¶„ì„ìš©)
        limit: ë¶„ì„í•  ì»¤ë°‹ ìˆ˜

    Returns:
        List[Dict]: ë²„ê·¸ ê´€ë ¨ ì»¤ë°‹ ë¦¬ìŠ¤íŠ¸
    """
    try:
        logger.info(f"Finding bug-related commits in {repo_path}")

        generator = DocumentGenerator(repo_path)
        try:
            commits = generator.get_commits(limit=limit)
        finally:
            generator.close()  # íŒŒì¼ í•¸ë“¤ í•´ì œ

        # ë²„ê·¸ ê´€ë ¨ í‚¤ì›Œë“œ
        bug_keywords = ['fix', 'bug', 'issue', 'patch', 'hotfix', 'bugfix', 'ìˆ˜ì •', 'ë²„ê·¸', 'ì˜¤ë¥˜']

        bug_commits = []
        for commit in commits:
            message_lower = commit['message'].lower()
            if any(keyword in message_lower for keyword in bug_keywords):
                bug_commits.append({
                    "id": commit['id'][:8],
                    "message": commit['message'],
                    "author": commit['author'],
                    "date": commit['date'][:10],
                    "files_changed": len(commit['files']),
                })

        logger.info(f"âœ“ Found {len(bug_commits)} bug-related commits")
        return bug_commits

    except Exception as e:
        logger.error(f"Error finding bug commits: {e}")
        return []

