"""
Azure AI Search Index ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°
ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸, í†µê³„, ê´€ë¦¬ ê¸°ëŠ¥ ì œê³µ
"""

import logging
from typing import Dict, List, Optional, Any
from azure.search.documents import SearchClient
from azure.search.documents.indexes import SearchIndexClient
from azure.core.exceptions import ResourceNotFoundError

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class IndexManager:
    """Azure AI Search ì¸ë±ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""

    def __init__(
        self,
        search_client: SearchClient,
        index_client: SearchIndexClient,
        index_name: str
    ):
        """
        Args:
            search_client: Azure AI Search í´ë¼ì´ì–¸íŠ¸
            index_client: Azure AI Search ì¸ë±ìŠ¤ í´ë¼ì´ì–¸íŠ¸
            index_name: ì¸ë±ìŠ¤ ì´ë¦„
        """
        self.search_client = search_client
        self.index_client = index_client
        self.index_name = index_name

    def get_index_statistics(self) -> Dict[str, Any]:
        """
        ì¸ë±ìŠ¤ í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        Returns:
            Dict: í†µê³„ ì •ë³´
        """
        try:
            logger.info(f"Getting statistics for index: {self.index_name}")

            # ì „ì²´ ë¬¸ì„œ ìˆ˜ ì¡°íšŒ
            results = self.search_client.search(
                search_text="*",
                include_total_count=True,
                top=0
            )

            total_count = results.get_count()

            # ì €ì¥ì†Œë³„ í†µê³„
            repo_stats = self._get_repository_statistics()

            # ê¸°ì—¬ìë³„ í†µê³„
            author_stats = self._get_author_statistics()

            # ë‚ ì§œ ë²”ìœ„
            date_range = self._get_date_range()

            return {
                "total_commits": total_count,
                "repositories": len(repo_stats),
                "total_authors": len(author_stats),
                "date_range": date_range,
                "repository_details": repo_stats,
                "top_authors": sorted(
                    author_stats.items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:10]
            }

        except Exception as e:
            logger.error(f"Failed to get index statistics: {e}")
            return {
                "error": str(e),
                "total_commits": 0
            }

    def _get_repository_statistics(self) -> Dict[str, int]:
        """ì €ì¥ì†Œë³„ ì»¤ë°‹ ìˆ˜ ì¡°íšŒ"""
        try:
            results = self.search_client.search(
                search_text="*",
                facets=["repo_id,count:1000"],
                top=0
            )

            repo_facets = results.get_facets()
            if not repo_facets or "repo_id" not in repo_facets:
                return {}

            repo_stats = {}
            for facet in repo_facets["repo_id"]:
                repo_id = facet.get("value", "unknown")
                count = facet.get("count", 0)
                repo_stats[repo_id] = count

            return repo_stats

        except Exception as e:
            logger.warning(f"Failed to get repository statistics: {e}")
            return {}

    def _get_author_statistics(self) -> Dict[str, int]:
        """ê¸°ì—¬ìë³„ ì»¤ë°‹ ìˆ˜ ì¡°íšŒ"""
        try:
            results = self.search_client.search(
                search_text="*",
                facets=["author,count:1000"],
                top=0
            )

            author_facets = results.get_facets()
            if not author_facets or "author" not in author_facets:
                return {}

            author_stats = {}
            for facet in author_facets["author"]:
                author = facet.get("value", "unknown")
                count = facet.get("count", 0)
                author_stats[author] = count

            return author_stats

        except Exception as e:
            logger.warning(f"Failed to get author statistics: {e}")
            return {}

    def _get_date_range(self) -> Dict[str, Optional[str]]:
        """ì»¤ë°‹ ë‚ ì§œ ë²”ìœ„ ì¡°íšŒ"""
        try:
            # ê°€ì¥ ì˜¤ë˜ëœ ì»¤ë°‹
            oldest = self.search_client.search(
                search_text="*",
                order_by=["date asc"],
                select=["date"],
                top=1
            )

            # ê°€ì¥ ìµœê·¼ ì»¤ë°‹
            newest = self.search_client.search(
                search_text="*",
                order_by=["date desc"],
                select=["date"],
                top=1
            )

            oldest_date = None
            newest_date = None

            for result in oldest:
                oldest_date = result.get("date")
                break

            for result in newest:
                newest_date = result.get("date")
                break

            return {
                "oldest": str(oldest_date) if oldest_date else None,
                "newest": str(newest_date) if newest_date else None
            }

        except Exception as e:
            logger.warning(f"Failed to get date range: {e}")
            return {"oldest": None, "newest": None}

    def list_indexed_repositories(self) -> List[Dict[str, Any]]:
        """
        ì¸ë±ì‹±ëœ ì €ì¥ì†Œ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

        Returns:
            List[Dict]: ì €ì¥ì†Œ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        try:
            logger.info("Listing indexed repositories")

            results = self.search_client.search(
                search_text="*",
                select=["repo_id", "repository_path"],
                top=1000
            )

            # repo_idë³„ë¡œ ê·¸ë£¹í™”
            repos = {}
            for result in results:
                repo_id = result.get("repo_id")
                repo_path = result.get("repository_path")

                if repo_id and repo_id not in repos:
                    repos[repo_id] = {
                        "repo_id": repo_id,
                        "repository_path": repo_path,
                        "commit_count": 0
                    }

                if repo_id:
                    repos[repo_id]["commit_count"] += 1

            return list(repos.values())

        except Exception as e:
            logger.error(f"Failed to list repositories: {e}")
            return []

    def delete_repository_commits(self, repo_id: str) -> int:
        """
        íŠ¹ì • ì €ì¥ì†Œì˜ ëª¨ë“  ì»¤ë°‹ì„ ì‚­ì œí•©ë‹ˆë‹¤.

        Args:
            repo_id: ì €ì¥ì†Œ ì‹ë³„ì

        Returns:
            int: ì‚­ì œëœ ë¬¸ì„œ ìˆ˜
        """
        try:
            logger.info(f"Deleting commits for repository: {repo_id}")

            # í•´ë‹¹ ì €ì¥ì†Œì˜ ëª¨ë“  ì»¤ë°‹ ID ì¡°íšŒ
            results = self.search_client.search(
                search_text="*",
                filter=f"repo_id eq '{repo_id}'",
                select=["id"],
                top=10000
            )

            commit_ids = [result["id"] for result in results]

            if not commit_ids:
                logger.info(f"No commits found for repo_id: {repo_id}")
                return 0

            # ë°°ì¹˜ ì‚­ì œ
            batch_size = 1000
            deleted_count = 0

            for i in range(0, len(commit_ids), batch_size):
                batch = commit_ids[i:i + batch_size]
                documents_to_delete = [{"id": doc_id} for doc_id in batch]

                result = self.search_client.delete_documents(documents_to_delete)
                deleted_count += len(batch)

                logger.info(f"Deleted batch {i//batch_size + 1}: {len(batch)} documents")

            logger.info(f"âœ“ Deleted {deleted_count} commits for repo_id: {repo_id}")
            return deleted_count

        except Exception as e:
            logger.error(f"Failed to delete repository commits: {e}")
            raise

    def clear_index(self) -> bool:
        """
        ì¸ë±ìŠ¤ì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤ (ì£¼ì˜: ì¸ë±ìŠ¤ êµ¬ì¡°ëŠ” ìœ ì§€ë¨).

        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        try:
            logger.warning("Clearing all documents from index")

            # ëª¨ë“  ë¬¸ì„œ ID ì¡°íšŒ
            results = self.search_client.search(
                search_text="*",
                select=["id"],
                top=10000
            )

            all_ids = [result["id"] for result in results]

            if not all_ids:
                logger.info("Index is already empty")
                return True

            # ë°°ì¹˜ ì‚­ì œ
            batch_size = 1000
            for i in range(0, len(all_ids), batch_size):
                batch = all_ids[i:i + batch_size]
                documents_to_delete = [{"id": doc_id} for doc_id in batch]
                self.search_client.delete_documents(documents_to_delete)

            logger.info(f"âœ“ Cleared {len(all_ids)} documents from index")
            return True

        except Exception as e:
            logger.error(f"Failed to clear index: {e}")
            return False

    def get_repository_info(self, repo_id: str) -> Optional[Dict[str, Any]]:
        """
        íŠ¹ì • ì €ì¥ì†Œì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            repo_id: ì €ì¥ì†Œ ì‹ë³„ì

        Returns:
            Dict: ì €ì¥ì†Œ ì •ë³´
        """
        try:
            logger.info(f"Getting info for repository: {repo_id}")

            # ì»¤ë°‹ ìˆ˜ ì¡°íšŒ
            results = self.search_client.search(
                search_text="*",
                filter=f"repo_id eq '{repo_id}'",
                include_total_count=True,
                top=0
            )

            commit_count = results.get_count()

            if commit_count == 0:
                logger.warning(f"No commits found for repo_id: {repo_id}")
                return None

            # ìƒ˜í”Œ ì»¤ë°‹ ì¡°íšŒ
            sample_results = self.search_client.search(
                search_text="*",
                filter=f"repo_id eq '{repo_id}'",
                select=["repository_path", "author", "date"],
                top=1
            )

            repo_path = None
            for result in sample_results:
                repo_path = result.get("repository_path")
                break

            # ê¸°ì—¬ì ì¡°íšŒ
            author_results = self.search_client.search(
                search_text="*",
                filter=f"repo_id eq '{repo_id}'",
                facets=["author,count:100"],
                top=0
            )

            author_facets = author_results.get_facets()
            author_count = len(author_facets.get("author", [])) if author_facets else 0

            # ë‚ ì§œ ë²”ìœ„
            oldest = self.search_client.search(
                search_text="*",
                filter=f"repo_id eq '{repo_id}'",
                order_by=["date asc"],
                select=["date"],
                top=1
            )

            newest = self.search_client.search(
                search_text="*",
                filter=f"repo_id eq '{repo_id}'",
                order_by=["date desc"],
                select=["date"],
                top=1
            )

            oldest_date = None
            newest_date = None

            for result in oldest:
                oldest_date = result.get("date")
                break

            for result in newest:
                newest_date = result.get("date")
                break

            return {
                "repo_id": repo_id,
                "repository_path": repo_path,
                "commit_count": commit_count,
                "author_count": author_count,
                "date_range": {
                    "oldest": str(oldest_date) if oldest_date else None,
                    "newest": str(newest_date) if newest_date else None
                }
            }

        except Exception as e:
            logger.error(f"Failed to get repository info: {e}")
            return None

    def check_index_health(self) -> Dict[str, Any]:
        """
        ì¸ë±ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

        Returns:
            Dict: ìƒíƒœ ì •ë³´
        """
        try:
            logger.info("Checking index health")

            # ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸
            try:
                index = self.index_client.get_index(self.index_name)
                index_exists = True
            except ResourceNotFoundError:
                index_exists = False
                return {
                    "status": "error",
                    "message": f"Index '{self.index_name}' does not exist"
                }

            # ë¬¸ì„œ ìˆ˜ í™•ì¸
            results = self.search_client.search(
                search_text="*",
                include_total_count=True,
                top=0
            )

            total_docs = results.get_count()

            # ìƒ˜í”Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
            test_results = self.search_client.search(
                search_text="test",
                top=1
            )

            search_works = True
            try:
                for _ in test_results:
                    break
            except Exception as e:
                search_works = False
                logger.warning(f"Search test failed: {e}")

            status = "healthy" if index_exists and search_works else "degraded"

            return {
                "status": status,
                "index_exists": index_exists,
                "total_documents": total_docs,
                "search_works": search_works,
                "index_name": self.index_name
            }

        except Exception as e:
            logger.error(f"Health check failed: {e}")
            return {
                "status": "error",
                "message": str(e)
            }


def format_index_statistics(stats: Dict[str, Any]) -> str:
    """
    í†µê³„ ì •ë³´ë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.

    Args:
        stats: get_index_statistics() ë°˜í™˜ê°’

    Returns:
        str: í¬ë§·íŒ…ëœ ë¬¸ìì—´
    """
    if "error" in stats:
        return f"âŒ ì˜¤ë¥˜: {stats['error']}"

    lines = [
        "ğŸ“Š **ì¸ë±ìŠ¤ í†µê³„**",
        "",
        f"ğŸ“¦ ì´ ì»¤ë°‹ ìˆ˜: {stats['total_commits']:,}",
        f"ğŸ—‚ï¸ ì €ì¥ì†Œ ìˆ˜: {stats['repositories']}",
        f"ğŸ‘¥ ê¸°ì—¬ì ìˆ˜: {stats['total_authors']}",
        "",
        "ğŸ“… **ë‚ ì§œ ë²”ìœ„**",
        f"  ê°€ì¥ ì˜¤ë˜ëœ ì»¤ë°‹: {stats['date_range']['oldest'] or 'N/A'}",
        f"  ê°€ì¥ ìµœê·¼ ì»¤ë°‹: {stats['date_range']['newest'] or 'N/A'}",
        "",
        "ğŸ† **Top 10 ê¸°ì—¬ì**"
    ]

    for author, count in stats.get("top_authors", [])[:10]:
        lines.append(f"  - {author}: {count} commits")

    if stats.get("repository_details"):
        lines.append("")
        lines.append("ğŸ“ **ì €ì¥ì†Œë³„ ì»¤ë°‹ ìˆ˜**")
        for repo_id, count in sorted(
            stats["repository_details"].items(),
            key=lambda x: x[1],
            reverse=True
        ):
            lines.append(f"  - {repo_id[:8]}...: {count} commits")

    return "\n".join(lines)

